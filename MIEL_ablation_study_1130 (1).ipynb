{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PRi2h93dP424",
        "outputId": "e18fec4f-a180-4a3b-ba2b-946497444f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.12/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.12/dist-packages (0.7.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "================================================================================\n",
            "MIEL-HAR Multi-Dataset Ablation Study (GPU Optimized)\n",
            "================================================================================\n",
            "Device: cuda\n",
            "\n",
            "GPU: Tesla T4\n",
            "CUDA Version: 12.6\n",
            "cuDNN Enabled: True\n",
            "cuDNN Benchmark: True\n",
            "\n",
            "================================================================================\n",
            "Loading All Datasets\n",
            "================================================================================\n",
            "\n",
            "############################################################\n",
            "Loading UCI-HAR...\n",
            "############################################################\n",
            "\n",
            "[UCI-HAR] Loading from: /content/drive/MyDrive/HAR_Dataset/UCI\n",
            "  [1/9] Loading: total_acc_x_train.txt\n",
            "  [2/9] Loading: total_acc_y_train.txt\n",
            "  [3/9] Loading: total_acc_z_train.txt\n",
            "  [4/9] Loading: body_acc_x_train.txt\n",
            "  [5/9] Loading: body_acc_y_train.txt\n",
            "  [6/9] Loading: body_acc_z_train.txt\n",
            "  [7/9] Loading: body_gyro_x_train.txt\n",
            "  [8/9] Loading: body_gyro_y_train.txt\n",
            "  [9/9] Loading: body_gyro_z_train.txt\n",
            "  [1/9] Loading: total_acc_x_test.txt\n",
            "  [2/9] Loading: total_acc_y_test.txt\n",
            "  [3/9] Loading: total_acc_z_test.txt\n",
            "  [4/9] Loading: body_acc_x_test.txt\n",
            "  [5/9] Loading: body_acc_y_test.txt\n",
            "  [6/9] Loading: body_acc_z_test.txt\n",
            "  [7/9] Loading: body_gyro_x_test.txt\n",
            "  [8/9] Loading: body_gyro_y_test.txt\n",
            "  [9/9] Loading: body_gyro_z_test.txt\n",
            "  Completed: Train (7352, 128, 9), Test (2947, 128, 9)\n",
            "Train: (7352, 128, 9) | Classes: 6\n",
            "Test: (2947, 128, 9) | Classes: 6\n",
            "Activity Names: ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
            "Train class distribution: {np.int64(0): 1226, np.int64(1): 1073, np.int64(2): 986, np.int64(3): 1286, np.int64(4): 1374, np.int64(5): 1407}\n",
            "Test class distribution: {np.int64(0): 496, np.int64(1): 471, np.int64(2): 420, np.int64(3): 491, np.int64(4): 532, np.int64(5): 537}\n",
            "\n",
            "############################################################\n",
            "Loading WISDM...\n",
            "############################################################\n",
            "\n",
            "[WISDM] Loading from: /content/drive/MyDrive/HAR_Dataset/WISDM\n",
            "  Found: WISDM_ar_v1.1_raw.txt\n",
            "  [1/1] Processing: WISDM_ar_v1.1_raw.txt\n",
            "  Completed: Train (19030, 80, 3), Test (8156, 80, 3)\n",
            "Train: (19030, 80, 3) | Classes: 6\n",
            "Test: (8156, 80, 3) | Classes: 6\n",
            "Activity Names: ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n",
            "Train class distribution: {np.int64(0): 1724, np.int64(1): 5953, np.int64(2): 1025, np.int64(3): 821, np.int64(4): 2118, np.int64(5): 7389}\n",
            "Test class distribution: {np.int64(0): 739, np.int64(1): 2552, np.int64(2): 439, np.int64(3): 352, np.int64(4): 907, np.int64(5): 3167}\n",
            "\n",
            "############################################################\n",
            "Loading PAMAP2...\n",
            "############################################################\n",
            "\n",
            "[PAMAP2] Loading from: /content/drive/MyDrive/HAR_Dataset/PAMAP2\n",
            "  Found 14 subject files\n",
            "  [1/14] Processing: subject101.dat\n",
            "  [2/14] Processing: subject102.dat\n",
            "  [3/14] Processing: subject103.dat\n",
            "  [4/14] Processing: subject104.dat\n",
            "  [5/14] Processing: subject105.dat\n",
            "  [6/14] Processing: subject106.dat\n",
            "  [7/14] Processing: subject107.dat\n",
            "  [8/14] Processing: subject108.dat\n",
            "  [9/14] Processing: subject109.dat\n",
            "  [10/14] Processing: subject101.dat\n",
            "  [11/14] Processing: subject105.dat\n",
            "  [12/14] Processing: subject106.dat\n",
            "  [13/14] Processing: subject108.dat\n",
            "  [14/14] Processing: subject109.dat\n",
            "  Completed: Train (27190, 100, 18), Test (11653, 100, 18)\n",
            "Train: (27190, 100, 18) | Classes: 12\n",
            "Test: (11653, 100, 18) | Classes: 12\n",
            "Activity Names: ['lying', 'sitting', 'standing', 'walking', 'running', 'cycling', 'Nordic walking', 'ascending stairs', 'descending stairs', 'vacuum cleaning', 'ironing', 'rope jumping']\n",
            "Train class distribution: {np.int64(0): 2692, np.int64(1): 2594, np.int64(2): 2658, np.int64(3): 3341, np.int64(4): 1373, np.int64(5): 2303, np.int64(6): 2634, np.int64(7): 1640, np.int64(8): 1471, np.int64(9): 2455, np.int64(10): 3342, np.int64(11): 687}\n",
            "Test class distribution: {np.int64(0): 1153, np.int64(1): 1111, np.int64(2): 1139, np.int64(3): 1432, np.int64(4): 589, np.int64(5): 987, np.int64(6): 1129, np.int64(7): 703, np.int64(8): 631, np.int64(9): 1052, np.int64(10): 1433, np.int64(11): 294}\n",
            "\n",
            "############################################################\n",
            "Loading MHEALTH...\n",
            "############################################################\n",
            "\n",
            "[MHEALTH] Loading from: /content/drive/MyDrive/HAR_Dataset/MHEALTH\n",
            "  Found 10 subject files\n",
            "  [1/10] Processing: mHealth_subject1.log\n",
            "  [2/10] Processing: mHealth_subject10.log\n",
            "  [3/10] Processing: mHealth_subject2.log\n",
            "  [4/10] Processing: mHealth_subject3.log\n",
            "  [5/10] Processing: mHealth_subject4.log\n",
            "  [6/10] Processing: mHealth_subject5.log\n",
            "  [7/10] Processing: mHealth_subject6.log\n",
            "  [8/10] Processing: mHealth_subject7.log\n",
            "  [9/10] Processing: mHealth_subject8.log\n",
            "  [10/10] Processing: mHealth_subject9.log\n",
            "  Completed: Train (9599, 50, 21), Test (4115, 50, 21)\n",
            "Train: (9599, 50, 21) | Classes: 12\n",
            "Test: (4115, 50, 21) | Classes: 12\n",
            "Activity Names: ['Standing still', 'Sitting and relaxing', 'Lying down', 'Walking', 'Climbing stairs', 'Waist bends forward', 'Frontal elevation of arms', 'Knees bending', 'Cycling', 'Jogging', 'Running', 'Jump front & back']\n",
            "Train class distribution: {np.int64(0): 857, np.int64(1): 861, np.int64(2): 861, np.int64(3): 861, np.int64(4): 853, np.int64(5): 793, np.int64(6): 823, np.int64(7): 822, np.int64(8): 859, np.int64(9): 861, np.int64(10): 861, np.int64(11): 287}\n",
            "Test class distribution: {np.int64(0): 367, np.int64(1): 369, np.int64(2): 369, np.int64(3): 369, np.int64(4): 366, np.int64(5): 340, np.int64(6): 353, np.int64(7): 352, np.int64(8): 369, np.int64(9): 369, np.int64(10): 369, np.int64(11): 123}\n",
            "\n",
            "############################################################\n",
            "Loading MOBIACT...\n",
            "############################################################\n",
            "\n",
            "[MobiAct] Loading from: /content/drive/MyDrive/HAR_Dataset/MOBIACT\n",
            "  Found 9 subjects\n",
            "  [1/9] Processing: sub10\n",
            "  [2/9] Processing: sub11\n",
            "  [3/9] Processing: sub2\n",
            "  [4/9] Processing: sub3\n",
            "  [5/9] Processing: sub4\n",
            "  [6/9] Processing: sub5\n",
            "  [7/9] Processing: sub7\n",
            "  [8/9] Processing: sub8\n",
            "  [9/9] Processing: sub9\n",
            "  Completed: Train (10882, 9, 100), Test (4665, 9, 100)\n",
            "Train: (10882, 9, 100) | Classes: 9\n",
            "Test: (4665, 9, 100) | Classes: 9\n",
            "Activity Names: [np.str_('CSI'), np.str_('CSO'), np.str_('JOG'), np.str_('JUM'), np.str_('SCH'), np.str_('STD'), np.str_('STN'), np.str_('STU'), np.str_('WAL')]\n",
            "Train class distribution: {np.int64(0): 302, np.int64(1): 295, np.int64(2): 978, np.int64(3): 972, np.int64(4): 310, np.int64(5): 3451, np.int64(6): 582, np.int64(7): 571, np.int64(8): 3421}\n",
            "Test class distribution: {np.int64(0): 130, np.int64(1): 127, np.int64(2): 420, np.int64(3): 416, np.int64(4): 133, np.int64(5): 1479, np.int64(6): 249, np.int64(7): 245, np.int64(8): 1466}\n",
            "\n",
            "############################################################\n",
            "Loading MOTIONSENSE...\n",
            "############################################################\n",
            "\n",
            "[MotionSense] Loading from: /content/drive/MyDrive/HAR_Dataset/MOTIONSENSE\n",
            "  Found 351 CSV files\n",
            "  Processing training files...\n",
            "    Processing file 1/280\n",
            "    Processing file 51/280\n",
            "    Processing file 101/280\n",
            "    Processing file 151/280\n",
            "    Processing file 201/280\n",
            "    Processing file 251/280\n",
            "  Processing validation files...\n",
            "    Processing file 1/71\n",
            "    Processing file 51/71\n",
            "  Completed: Train (16010, 12, 128), Test (4510, 12, 128)\n",
            "Train: (16010, 12, 128) | Classes: 6\n",
            "Test: (4510, 12, 128) | Classes: 6\n",
            "Activity Names: ['dws', 'jog', 'sit', 'std', 'ups', 'wlk']\n",
            "Train class distribution: {np.int64(0): 1645, np.int64(1): 1912, np.int64(2): 3806, np.int64(3): 3720, np.int64(4): 1710, np.int64(5): 3217}\n",
            "Test class distribution: {np.int64(0): 307, np.int64(1): 113, np.int64(2): 1415, np.int64(3): 996, np.int64(4): 640, np.int64(5): 1039}\n",
            "\n",
            "############################################################\n",
            "Loading UNIMIB...\n",
            "############################################################\n",
            "\n",
            "[UNIMIB] Loading from: /content/drive/MyDrive/HAR_Dataset/UNIMIB (1)\n",
            "  Processing: unimib_train.csv\n",
            "  Processing: unimib_test.csv\n",
            "  Processing: unimib_val.csv\n",
            "  Completed: Train (9417, 3, 151), Test (2354, 3, 151)\n",
            "Train: (9417, 3, 151) | Classes: 17\n",
            "Test: (2354, 3, 151) | Classes: 17\n",
            "Activity Names: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17']\n",
            "Train class distribution: {np.int64(0): 228, np.int64(1): 317, np.int64(2): 1342, np.int64(3): 1556, np.int64(4): 726, np.int64(5): 597, np.int64(6): 1024, np.int64(7): 233, np.int64(8): 157, np.int64(9): 412, np.int64(10): 394, np.int64(11): 400, np.int64(12): 512, np.int64(13): 372, np.int64(14): 337, np.int64(15): 395, np.int64(16): 415}\n",
            "Test class distribution: {np.int64(0): 58, np.int64(1): 80, np.int64(2): 336, np.int64(3): 388, np.int64(4): 182, np.int64(5): 148, np.int64(6): 256, np.int64(7): 58, np.int64(8): 40, np.int64(9): 102, np.int64(10): 98, np.int64(11): 100, np.int64(12): 128, np.int64(13): 94, np.int64(14): 84, np.int64(15): 98, np.int64(16): 104}\n",
            "\n",
            "================================================================================\n",
            "Successfully loaded 7 datasets\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UCI-HAR - Full Model (Ours)\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 2.33ms\n",
            "Input: (128, 9) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.0115     0.8806     0.8793     0.8838     0.8797     (*)\n",
            "6        0.000965   0.5165     0.9172     0.9178     0.9179     0.9186    \n",
            "11       0.000885   0.4949     0.9247     0.9243     0.9301     0.9246    \n",
            "16       0.000768   0.4727     0.9260     0.9253     0.9287     0.9259    \n",
            "21       0.000624   0.4579     0.9226     0.9214     0.9300     0.9219    \n",
            "26       0.000469   0.4509     0.9298     0.9293     0.9303     0.9301    \n",
            "31       0.000316   0.4470     0.9277     0.9272     0.9292     0.9278    \n",
            "36       0.000181   0.4428     0.9274     0.9269     0.9278     0.9278    \n",
            "41       0.000078   0.4367     0.9298     0.9291     0.9306     0.9299    \n",
            "46       0.000016   0.4350     0.9304     0.9299     0.9312     0.9307    \n",
            "50       0.000000   0.4349     0.9298     0.9292     0.9305     0.9300    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9325 | F1: 0.9320 | Prec: 0.9328 | Rec: 0.9327\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 2.33ms\n",
            "\n",
            "Generating t-SNE plot for UCI-HAR - Full Model (Ours)...\n",
            "\n",
            "============================================================\n",
            "Training UCI-HAR - w/o Physics Priors\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 31.62M | Inf: 1.43ms\n",
            "Input: (128, 9) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        0.000999   0.9600     0.8962     0.8955     0.9039     0.8938     (*)\n",
            "6        0.000965   0.5145     0.9179     0.9180     0.9193     0.9185     (*)\n",
            "11       0.000885   0.4968     0.9220     0.9217     0.9269     0.9220    \n",
            "16       0.000768   0.4750     0.9379     0.9380     0.9384     0.9383     (*)\n",
            "21       0.000624   0.4618     0.9301     0.9301     0.9303     0.9302    \n",
            "26       0.000469   0.4506     0.9420     0.9417     0.9438     0.9417    \n",
            "31       0.000316   0.4427     0.9505     0.9501     0.9519     0.9503     (*)\n",
            "36       0.000181   0.4377     0.9416     0.9418     0.9434     0.9419    \n",
            "41       0.000078   0.4347     0.9420     0.9422     0.9431     0.9425    \n",
            "46       0.000016   0.4338     0.9420     0.9421     0.9432     0.9424    \n",
            "50       0.000000   0.4332     0.9410     0.9411     0.9421     0.9414    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9505 | F1: 0.9501 | Prec: 0.9519 | Rec: 0.9503\n",
            "Params: 0.14M | FLOPs: 31.62M | Inf: 1.43ms\n",
            "\n",
            "Generating t-SNE plot for UCI-HAR - w/o Physics Priors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UCI-HAR - Fixed Physics\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 2.34ms\n",
            "Input: (128, 9) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   0.9519     0.8751     0.8729     0.8802     0.8749     (*)\n",
            "6        0.000965   0.5150     0.9186     0.9182     0.9233     0.9193    \n",
            "11       0.000885   0.4952     0.9399     0.9400     0.9400     0.9410    \n",
            "16       0.000768   0.4715     0.9264     0.9260     0.9330     0.9269    \n",
            "21       0.000624   0.4621     0.9410     0.9408     0.9422     0.9416    \n",
            "26       0.000469   0.4474     0.9376     0.9374     0.9391     0.9382    \n",
            "31       0.000316   0.4421     0.9410     0.9410     0.9420     0.9418    \n",
            "36       0.000181   0.4399     0.9386     0.9385     0.9406     0.9391    \n",
            "41       0.000078   0.4351     0.9433     0.9432     0.9454     0.9438    \n",
            "46       0.000016   0.4338     0.9403     0.9401     0.9427     0.9407    \n",
            "50       0.000000   0.4338     0.9403     0.9401     0.9425     0.9407    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9477 | F1: 0.9479 | Prec: 0.9489 | Rec: 0.9478\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 2.34ms\n",
            "\n",
            "Generating t-SNE plot for UCI-HAR - Fixed Physics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UCI-HAR - w/o Physics Gradient\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 1.98ms\n",
            "Input: (128, 9) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   0.9439     0.8846     0.8835     0.8857     0.8854     (*)\n",
            "6        0.000965   0.5160     0.9260     0.9264     0.9287     0.9271    \n",
            "11       0.000885   0.4942     0.9145     0.9130     0.9235     0.9144    \n",
            "16       0.000768   0.4715     0.9359     0.9351     0.9378     0.9357    \n",
            "21       0.000624   0.4661     0.9379     0.9377     0.9377     0.9385    \n",
            "26       0.000469   0.4529     0.9474     0.9468     0.9500     0.9471    \n",
            "31       0.000316   0.4436     0.9308     0.9307     0.9330     0.9310    \n",
            "36       0.000181   0.4371     0.9423     0.9419     0.9447     0.9421    \n",
            "41       0.000078   0.4347     0.9433     0.9430     0.9452     0.9433    \n",
            "46       0.000016   0.4333     0.9437     0.9433     0.9456     0.9436    \n",
            "50       0.000000   0.4328     0.9433     0.9430     0.9454     0.9433    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9481 | F1: 0.9477 | Prec: 0.9493 | Rec: 0.9479\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 1.98ms\n",
            "\n",
            "Generating t-SNE plot for UCI-HAR - w/o Physics Gradient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UCI-HAR - w/o Landscape Enc\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 34.31M | Inf: 2.02ms\n",
            "Input: (128, 9) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.4201     0.7201     0.6566     0.6657     0.6948     (*)\n",
            "6        0.000965   0.4700     0.9634     0.9637     0.9651     0.9637     (*)\n",
            "11       0.000885   0.4496     0.9671     0.9677     0.9695     0.9675     (*)\n",
            "16       0.000768   0.4453     0.9603     0.9609     0.9641     0.9607    \n",
            "21       0.000624   0.4385     0.9593     0.9600     0.9628     0.9598    \n",
            "26       0.000469   0.4366     0.9576     0.9581     0.9605     0.9580    \n",
            "31       0.000316   0.4346     0.9559     0.9564     0.9594     0.9564    \n",
            "36       0.000181   0.4340     0.9572     0.9578     0.9601     0.9577    \n",
            "41       0.000078   0.4333     0.9562     0.9567     0.9595     0.9567    \n",
            "46       0.000016   0.4330     0.9542     0.9547     0.9579     0.9547    \n",
            "50       0.000000   0.4332     0.9552     0.9557     0.9587     0.9557    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9671 | F1: 0.9677 | Prec: 0.9695 | Rec: 0.9675\n",
            "Params: 0.15M | FLOPs: 34.31M | Inf: 2.02ms\n",
            "\n",
            "Generating t-SNE plot for UCI-HAR - w/o Landscape Enc...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UCI-HAR - w/o Energy Loss\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 2.30ms\n",
            "Input: (128, 9) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   0.9533     0.8728     0.8705     0.8742     0.8700     (*)\n",
            "6        0.000965   0.5171     0.9233     0.9235     0.9262     0.9245     (*)\n",
            "11       0.000885   0.5024     0.9369     0.9372     0.9391     0.9380    \n",
            "16       0.000768   0.4790     0.9389     0.9394     0.9395     0.9404    \n",
            "21       0.000624   0.4773     0.9423     0.9423     0.9450     0.9430    \n",
            "26       0.000469   0.4589     0.9433     0.9435     0.9445     0.9443    \n",
            "31       0.000316   0.4512     0.9481     0.9480     0.9497     0.9486    \n",
            "36       0.000181   0.4457     0.9440     0.9440     0.9452     0.9448    \n",
            "41       0.000078   0.4410     0.9457     0.9456     0.9472     0.9464    \n",
            "46       0.000016   0.4376     0.9440     0.9442     0.9450     0.9450    \n",
            "50       0.000000   0.4374     0.9433     0.9435     0.9447     0.9442    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9481 | F1: 0.9486 | Prec: 0.9490 | Rec: 0.9492\n",
            "Params: 0.14M | FLOPs: 31.69M | Inf: 2.30ms\n",
            "\n",
            "Generating t-SNE plot for UCI-HAR - w/o Energy Loss...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training WISDM - Full Model (Ours)\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 2.05ms\n",
            "Input: (80, 3) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.0088     0.8315     0.7411     0.8580     0.7264     (*)\n",
            "6        0.000965   0.5042     0.9776     0.9694     0.9690     0.9699     (*)\n",
            "11       0.000885   0.4679     0.9871     0.9803     0.9812     0.9796     (*)\n",
            "16       0.000768   0.4586     0.9865     0.9807     0.9792     0.9823    \n",
            "21       0.000624   0.4463     0.9904     0.9866     0.9873     0.9859    \n",
            "26       0.000469   0.4445     0.9919     0.9881     0.9877     0.9886     (*)\n",
            "31       0.000316   0.4414     0.9920     0.9883     0.9881     0.9886    \n",
            "36       0.000181   0.4384     0.9925     0.9889     0.9895     0.9883    \n",
            "41       0.000078   0.4375     0.9934     0.9901     0.9902     0.9900    \n",
            "46       0.000016   0.4366     0.9935     0.9902     0.9901     0.9902    \n",
            "50       0.000000   0.4365     0.9931     0.9897     0.9897     0.9896    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9936 | F1: 0.9904 | Prec: 0.9903 | Rec: 0.9905\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 2.05ms\n",
            "\n",
            "Generating t-SNE plot for WISDM - Full Model (Ours)...\n",
            "\n",
            "============================================================\n",
            "Training WISDM - w/o Physics Priors\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 19.16M | Inf: 1.13ms\n",
            "Input: (80, 3) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        0.000999   1.0072     0.8450     0.7660     0.8741     0.7424     (*)\n",
            "6        0.000965   0.5005     0.9739     0.9577     0.9620     0.9542     (*)\n",
            "11       0.000885   0.4677     0.9880     0.9818     0.9822     0.9813     (*)\n",
            "16       0.000768   0.4593     0.9858     0.9796     0.9824     0.9770    \n",
            "21       0.000624   0.4491     0.9909     0.9864     0.9867     0.9861     (*)\n",
            "26       0.000469   0.4458     0.9893     0.9837     0.9841     0.9834    \n",
            "31       0.000316   0.4406     0.9926     0.9887     0.9889     0.9886     (*)\n",
            "36       0.000181   0.4381     0.9926     0.9888     0.9892     0.9885    \n",
            "41       0.000078   0.4372     0.9924     0.9885     0.9888     0.9882    \n",
            "46       0.000016   0.4365     0.9924     0.9885     0.9888     0.9882    \n",
            "50       0.000000   0.4365     0.9925     0.9887     0.9889     0.9885    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9933 | F1: 0.9895 | Prec: 0.9893 | Rec: 0.9898\n",
            "Params: 0.14M | FLOPs: 19.16M | Inf: 1.13ms\n",
            "\n",
            "Generating t-SNE plot for WISDM - w/o Physics Priors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training WISDM - Fixed Physics\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 2.87ms\n",
            "Input: (80, 3) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   0.9938     0.8453     0.7785     0.8321     0.7607     (*)\n",
            "6        0.000965   0.4943     0.9777     0.9676     0.9685     0.9670     (*)\n",
            "11       0.000885   0.4693     0.9857     0.9795     0.9792     0.9802     (*)\n",
            "16       0.000768   0.4523     0.9886     0.9830     0.9837     0.9825    \n",
            "21       0.000624   0.4469     0.9830     0.9765     0.9839     0.9703    \n",
            "26       0.000469   0.4431     0.9926     0.9886     0.9892     0.9881     (*)\n",
            "31       0.000316   0.4390     0.9926     0.9886     0.9890     0.9882    \n",
            "36       0.000181   0.4372     0.9936     0.9899     0.9901     0.9898     (*)\n",
            "41       0.000078   0.4362     0.9935     0.9899     0.9905     0.9893    \n",
            "46       0.000016   0.4355     0.9936     0.9900     0.9905     0.9896    \n",
            "50       0.000000   0.4355     0.9936     0.9900     0.9905     0.9896    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9939 | F1: 0.9904 | Prec: 0.9909 | Rec: 0.9899\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 2.87ms\n",
            "\n",
            "Generating t-SNE plot for WISDM - Fixed Physics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training WISDM - w/o Physics Gradient\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 1.76ms\n",
            "Input: (80, 3) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.0482     0.8271     0.7188     0.8027     0.7210     (*)\n",
            "6        0.000965   0.5086     0.9705     0.9559     0.9603     0.9524     (*)\n",
            "11       0.000885   0.4716     0.9825     0.9751     0.9770     0.9734    \n",
            "16       0.000768   0.4561     0.9874     0.9813     0.9844     0.9789    \n",
            "21       0.000624   0.4506     0.9895     0.9846     0.9856     0.9837    \n",
            "26       0.000469   0.4495     0.9910     0.9865     0.9862     0.9868     (*)\n",
            "31       0.000316   0.4409     0.9926     0.9891     0.9901     0.9882     (*)\n",
            "36       0.000181   0.4388     0.9928     0.9893     0.9903     0.9884     (*)\n",
            "41       0.000078   0.4377     0.9926     0.9891     0.9893     0.9890    \n",
            "46       0.000016   0.4374     0.9926     0.9893     0.9900     0.9887    \n",
            "50       0.000000   0.4369     0.9926     0.9893     0.9900     0.9887    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9929 | F1: 0.9894 | Prec: 0.9900 | Rec: 0.9888\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 1.76ms\n",
            "\n",
            "Generating t-SNE plot for WISDM - w/o Physics Gradient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 1177, in <cell line: 0>\n",
            "    result = train_single_dataset(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 976, in train_single_dataset\n",
            "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 929, in compute_flops_params\n",
            "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thop/profile.py\", line 212, in profile\n",
            "    model(*inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 787, in forward\n",
            "    landscape_features = self.landscape_encoder(energy, gradient, x)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 758, in forward\n",
            "    x = self.encoder(landscape_state.transpose(1, 2))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\", line 229, in forward\n",
            "    return F.layer_norm(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2901, in layer_norm\n",
            "    return torch.layer_norm(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 80]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error training WISDM with w/o Landscape Enc: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 80]\n",
            "\n",
            "============================================================\n",
            "Training WISDM - w/o Energy Loss\n",
            "============================================================\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 2.06ms\n",
            "Input: (80, 3) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.0556     0.8201     0.7245     0.7625     0.7339     (*)\n",
            "6        0.000965   0.5063     0.9735     0.9567     0.9626     0.9529     (*)\n",
            "11       0.000885   0.4708     0.9822     0.9755     0.9820     0.9699    \n",
            "16       0.000768   0.4556     0.9896     0.9847     0.9856     0.9838     (*)\n",
            "21       0.000624   0.4453     0.9912     0.9861     0.9871     0.9854     (*)\n",
            "26       0.000469   0.4404     0.9922     0.9885     0.9902     0.9870    \n",
            "31       0.000316   0.4390     0.9918     0.9873     0.9887     0.9861    \n",
            "36       0.000181   0.4365     0.9929     0.9885     0.9894     0.9878    \n",
            "41       0.000078   0.4347     0.9934     0.9895     0.9899     0.9891    \n",
            "46       0.000016   0.4339     0.9931     0.9893     0.9899     0.9888    \n",
            "50       0.000000   0.4340     0.9934     0.9896     0.9900     0.9892    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9934 | F1: 0.9894 | Prec: 0.9892 | Rec: 0.9896\n",
            "Params: 0.14M | FLOPs: 19.20M | Inf: 2.06ms\n",
            "\n",
            "Generating t-SNE plot for WISDM - w/o Energy Loss...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training PAMAP2 - Full Model (Ours)\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.22ms\n",
            "Input: (100, 18) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.1984     0.8878     0.8851     0.9075     0.8705     (*)\n",
            "6        0.000965   0.7279     0.9293     0.9266     0.9367     0.9187     (*)\n",
            "11       0.000885   0.6807     0.9393     0.9362     0.9420     0.9320     (*)\n",
            "16       0.000768   0.6478     0.9412     0.9403     0.9464     0.9359    \n",
            "21       0.000624   0.6213     0.9551     0.9537     0.9575     0.9504     (*)\n",
            "26       0.000469   0.6006     0.9562     0.9555     0.9601     0.9515    \n",
            "31       0.000316   0.5862     0.9619     0.9607     0.9634     0.9584    \n",
            "36       0.000181   0.5751     0.9631     0.9617     0.9646     0.9593     (*)\n",
            "41       0.000078   0.5697     0.9646     0.9636     0.9659     0.9615    \n",
            "46       0.000016   0.5664     0.9662     0.9648     0.9670     0.9628     (*)\n",
            "50       0.000000   0.5652     0.9660     0.9650     0.9672     0.9629    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9664 | F1: 0.9654 | Prec: 0.9677 | Rec: 0.9633\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.22ms\n",
            "\n",
            "Generating t-SNE plot for PAMAP2 - Full Model (Ours)...\n",
            "\n",
            "============================================================\n",
            "Training PAMAP2 - w/o Physics Priors\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 25.87M | Inf: 1.20ms\n",
            "Input: (100, 18) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        0.000999   1.1455     0.8882     0.8862     0.9053     0.8740     (*)\n",
            "6        0.000965   0.7301     0.9353     0.9331     0.9425     0.9263     (*)\n",
            "11       0.000885   0.6764     0.9406     0.9386     0.9471     0.9329     (*)\n",
            "16       0.000768   0.6455     0.9489     0.9461     0.9510     0.9421     (*)\n",
            "21       0.000624   0.6200     0.9553     0.9530     0.9584     0.9486     (*)\n",
            "26       0.000469   0.6071     0.9561     0.9548     0.9618     0.9489     (*)\n",
            "31       0.000316   0.5881     0.9601     0.9587     0.9632     0.9549    \n",
            "36       0.000181   0.5795     0.9607     0.9591     0.9637     0.9552    \n",
            "41       0.000078   0.5731     0.9631     0.9614     0.9650     0.9584    \n",
            "46       0.000016   0.5709     0.9644     0.9631     0.9662     0.9604    \n",
            "50       0.000000   0.5693     0.9649     0.9639     0.9671     0.9610    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9652 | F1: 0.9640 | Prec: 0.9672 | Rec: 0.9612\n",
            "Params: 0.15M | FLOPs: 25.87M | Inf: 1.20ms\n",
            "\n",
            "Generating t-SNE plot for PAMAP2 - w/o Physics Priors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training PAMAP2 - Fixed Physics\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.37ms\n",
            "Input: (100, 18) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.1759     0.8895     0.8872     0.9077     0.8751     (*)\n",
            "6        0.000965   0.7335     0.9286     0.9259     0.9369     0.9183     (*)\n",
            "11       0.000885   0.6844     0.9407     0.9385     0.9459     0.9327     (*)\n",
            "16       0.000768   0.6432     0.9495     0.9478     0.9551     0.9419    \n",
            "21       0.000624   0.6152     0.9535     0.9514     0.9578     0.9462    \n",
            "26       0.000469   0.5961     0.9586     0.9572     0.9624     0.9527     (*)\n",
            "31       0.000316   0.5841     0.9622     0.9603     0.9636     0.9575    \n",
            "36       0.000181   0.5764     0.9665     0.9656     0.9686     0.9628     (*)\n",
            "41       0.000078   0.5698     0.9675     0.9662     0.9691     0.9636     (*)\n",
            "46       0.000016   0.5671     0.9680     0.9669     0.9697     0.9644    \n",
            "50       0.000000   0.5659     0.9676     0.9667     0.9697     0.9640    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9683 | F1: 0.9670 | Prec: 0.9696 | Rec: 0.9646\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.37ms\n",
            "\n",
            "Generating t-SNE plot for PAMAP2 - Fixed Physics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training PAMAP2 - w/o Physics Gradient\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.01ms\n",
            "Input: (100, 18) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.1842     0.8793     0.8770     0.8930     0.8676     (*)\n",
            "6        0.000965   0.7339     0.9277     0.9264     0.9358     0.9196     (*)\n",
            "11       0.000885   0.6844     0.9356     0.9330     0.9393     0.9291     (*)\n",
            "16       0.000768   0.6551     0.9459     0.9445     0.9486     0.9410     (*)\n",
            "21       0.000624   0.6206     0.9517     0.9503     0.9530     0.9484     (*)\n",
            "26       0.000469   0.6063     0.9574     0.9561     0.9606     0.9521     (*)\n",
            "31       0.000316   0.5904     0.9588     0.9577     0.9613     0.9545     (*)\n",
            "36       0.000181   0.5843     0.9604     0.9593     0.9629     0.9562    \n",
            "41       0.000078   0.5749     0.9616     0.9604     0.9644     0.9568    \n",
            "46       0.000016   0.5724     0.9622     0.9614     0.9649     0.9582    \n",
            "50       0.000000   0.5708     0.9625     0.9615     0.9651     0.9583    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9625 | F1: 0.9616 | Prec: 0.9652 | Rec: 0.9583\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.01ms\n",
            "\n",
            "Generating t-SNE plot for PAMAP2 - w/o Physics Gradient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 1177, in <cell line: 0>\n",
            "    result = train_single_dataset(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 976, in train_single_dataset\n",
            "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 929, in compute_flops_params\n",
            "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thop/profile.py\", line 212, in profile\n",
            "    model(*inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 787, in forward\n",
            "    landscape_features = self.landscape_encoder(energy, gradient, x)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 758, in forward\n",
            "    x = self.encoder(landscape_state.transpose(1, 2))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\", line 229, in forward\n",
            "    return F.layer_norm(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2901, in layer_norm\n",
            "    return torch.layer_norm(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error training PAMAP2 with w/o Landscape Enc: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 100]\n",
            "\n",
            "============================================================\n",
            "Training PAMAP2 - w/o Energy Loss\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.29ms\n",
            "Input: (100, 18) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.1821     0.8836     0.8818     0.9033     0.8681     (*)\n",
            "6        0.000965   0.7238     0.9260     0.9254     0.9371     0.9170     (*)\n",
            "11       0.000885   0.6781     0.9402     0.9373     0.9448     0.9316    \n",
            "16       0.000768   0.6408     0.9441     0.9422     0.9476     0.9381    \n",
            "21       0.000624   0.6184     0.9520     0.9500     0.9542     0.9465     (*)\n",
            "26       0.000469   0.5978     0.9557     0.9535     0.9588     0.9489    \n",
            "31       0.000316   0.5849     0.9598     0.9585     0.9626     0.9552     (*)\n",
            "36       0.000181   0.5742     0.9621     0.9609     0.9645     0.9579     (*)\n",
            "41       0.000078   0.5685     0.9633     0.9627     0.9656     0.9601     (*)\n",
            "46       0.000016   0.5658     0.9632     0.9621     0.9651     0.9595    \n",
            "50       0.000000   0.5650     0.9634     0.9621     0.9652     0.9594    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9638 | F1: 0.9625 | Prec: 0.9652 | Rec: 0.9601\n",
            "Params: 0.15M | FLOPs: 25.92M | Inf: 2.29ms\n",
            "\n",
            "Generating t-SNE plot for PAMAP2 - w/o Energy Loss...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MHEALTH - Full Model (Ours)\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.21ms\n",
            "Input: (50, 21) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.3674     0.9300     0.9277     0.9351     0.9235     (*)\n",
            "6        0.000965   0.5597     0.9961     0.9963     0.9963     0.9963     (*)\n",
            "11       0.000885   0.5493     0.9964     0.9965     0.9966     0.9965    \n",
            "16       0.000768   0.5454     0.9964     0.9965     0.9966     0.9965    \n",
            "21       0.000624   0.5440     0.9964     0.9965     0.9966     0.9965    \n",
            "26       0.000469   0.5427     0.9961     0.9959     0.9955     0.9963    \n",
            "31       0.000316   0.5420     0.9964     0.9963     0.9961     0.9965    \n",
            "36       0.000181   0.5419     0.9964     0.9963     0.9961     0.9965    \n",
            "41       0.000078   0.5415     0.9961     0.9961     0.9959     0.9963    \n",
            "46       0.000016   0.5411     0.9961     0.9961     0.9959     0.9963    \n",
            "50       0.000000   0.5413     0.9961     0.9961     0.9959     0.9963    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9968 | F1: 0.9970 | Prec: 0.9970 | Rec: 0.9970\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.21ms\n",
            "\n",
            "Generating t-SNE plot for MHEALTH - Full Model (Ours)...\n",
            "\n",
            "============================================================\n",
            "Training MHEALTH - w/o Physics Priors\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 13.14M | Inf: 1.12ms\n",
            "Input: (50, 21) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        0.000999   1.2986     0.9439     0.9447     0.9506     0.9441     (*)\n",
            "6        0.000965   0.5581     0.9956     0.9956     0.9954     0.9959     (*)\n",
            "11       0.000885   0.5484     0.9966     0.9965     0.9963     0.9967    \n",
            "16       0.000768   0.5448     0.9971     0.9970     0.9968     0.9972    \n",
            "21       0.000624   0.5433     0.9971     0.9970     0.9968     0.9972    \n",
            "26       0.000469   0.5425     0.9971     0.9970     0.9968     0.9972    \n",
            "31       0.000316   0.5419     0.9968     0.9968     0.9966     0.9970    \n",
            "36       0.000181   0.5413     0.9973     0.9972     0.9971     0.9974    \n",
            "41       0.000078   0.5413     0.9973     0.9972     0.9971     0.9974    \n",
            "46       0.000016   0.5412     0.9973     0.9972     0.9971     0.9974    \n",
            "50       0.000000   0.5411     0.9973     0.9972     0.9971     0.9974    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9976 | F1: 0.9975 | Prec: 0.9973 | Rec: 0.9977\n",
            "Params: 0.15M | FLOPs: 13.14M | Inf: 1.12ms\n",
            "\n",
            "Generating t-SNE plot for MHEALTH - w/o Physics Priors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MHEALTH - Fixed Physics\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.37ms\n",
            "Input: (50, 21) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.3625     0.9358     0.9350     0.9436     0.9333     (*)\n",
            "6        0.000965   0.5558     0.9968     0.9968     0.9966     0.9970     (*)\n",
            "11       0.000885   0.5477     0.9968     0.9970     0.9971     0.9970    \n",
            "16       0.000768   0.5443     0.9973     0.9972     0.9971     0.9974    \n",
            "21       0.000624   0.5427     0.9976     0.9975     0.9973     0.9977    \n",
            "26       0.000469   0.5420     0.9976     0.9975     0.9973     0.9977    \n",
            "31       0.000316   0.5413     0.9971     0.9968     0.9964     0.9972    \n",
            "36       0.000181   0.5413     0.9971     0.9968     0.9964     0.9972    \n",
            "41       0.000078   0.5409     0.9971     0.9968     0.9964     0.9972    \n",
            "46       0.000016   0.5407     0.9971     0.9968     0.9964     0.9972    \n",
            "50       0.000000   0.5407     0.9971     0.9968     0.9964     0.9972    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9978 | F1: 0.9979 | Prec: 0.9980 | Rec: 0.9979\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.37ms\n",
            "\n",
            "Generating t-SNE plot for MHEALTH - Fixed Physics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MHEALTH - w/o Physics Gradient\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.00ms\n",
            "Input: (50, 21) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.3240     0.9473     0.9477     0.9518     0.9456     (*)\n",
            "6        0.000965   0.5592     0.9966     0.9966     0.9964     0.9968     (*)\n",
            "11       0.000885   0.5487     0.9973     0.9972     0.9970     0.9975     (*)\n",
            "16       0.000768   0.5446     0.9971     0.9970     0.9968     0.9972    \n",
            "21       0.000624   0.5435     0.9973     0.9972     0.9970     0.9975    \n",
            "26       0.000469   0.5426     0.9973     0.9972     0.9970     0.9975    \n",
            "31       0.000316   0.5417     0.9968     0.9968     0.9966     0.9970    \n",
            "36       0.000181   0.5413     0.9973     0.9972     0.9970     0.9975    \n",
            "41       0.000078   0.5411     0.9971     0.9968     0.9964     0.9972    \n",
            "46       0.000016   0.5408     0.9973     0.9972     0.9970     0.9975    \n",
            "50       0.000000   0.5408     0.9973     0.9972     0.9970     0.9975    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9973 | F1: 0.9972 | Prec: 0.9970 | Rec: 0.9975\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.00ms\n",
            "\n",
            "Generating t-SNE plot for MHEALTH - w/o Physics Gradient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 1177, in <cell line: 0>\n",
            "    result = train_single_dataset(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 976, in train_single_dataset\n",
            "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 929, in compute_flops_params\n",
            "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thop/profile.py\", line 212, in profile\n",
            "    model(*inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 787, in forward\n",
            "    landscape_features = self.landscape_encoder(energy, gradient, x)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 758, in forward\n",
            "    x = self.encoder(landscape_state.transpose(1, 2))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\", line 229, in forward\n",
            "    return F.layer_norm(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2901, in layer_norm\n",
            "    return torch.layer_norm(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 50]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error training MHEALTH with w/o Landscape Enc: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 50]\n",
            "\n",
            "============================================================\n",
            "Training MHEALTH - w/o Energy Loss\n",
            "============================================================\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.48ms\n",
            "Input: (50, 21) | Classes: 12\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.3465     0.9171     0.9069     0.9256     0.9002     (*)\n",
            "6        0.000965   0.5593     0.9956     0.9956     0.9954     0.9958    \n",
            "11       0.000885   0.5478     0.9961     0.9961     0.9959     0.9963    \n",
            "16       0.000768   0.5439     0.9968     0.9968     0.9966     0.9970    \n",
            "21       0.000624   0.5425     0.9968     0.9968     0.9966     0.9970    \n",
            "26       0.000469   0.5412     0.9966     0.9966     0.9964     0.9968    \n",
            "31       0.000316   0.5406     0.9968     0.9970     0.9970     0.9970    \n",
            "36       0.000181   0.5399     0.9968     0.9970     0.9970     0.9970    \n",
            "41       0.000078   0.5400     0.9966     0.9966     0.9964     0.9968    \n",
            "46       0.000016   0.5398     0.9966     0.9966     0.9964     0.9968    \n",
            "50       0.000000   0.5395     0.9966     0.9966     0.9964     0.9968    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9968 | F1: 0.9968 | Prec: 0.9966 | Rec: 0.9970\n",
            "Params: 0.15M | FLOPs: 13.17M | Inf: 2.48ms\n",
            "\n",
            "Generating t-SNE plot for MHEALTH - w/o Energy Loss...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MOBIACT - Full Model (Ours)\n",
            "============================================================\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.38ms\n",
            "Input: (9, 100) | Classes: 9\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.4541     0.6624     0.3178     0.4256     0.3390     (*)\n",
            "6        0.000965   0.6546     0.9378     0.8427     0.8756     0.8366     (*)\n",
            "11       0.000885   0.5707     0.9520     0.9050     0.9282     0.8862    \n",
            "16       0.000768   0.5433     0.9625     0.9231     0.9331     0.9176     (*)\n",
            "21       0.000624   0.5286     0.9629     0.9293     0.9429     0.9171     (*)\n",
            "26       0.000469   0.5194     0.9640     0.9306     0.9431     0.9195    \n",
            "31       0.000316   0.5146     0.9621     0.9287     0.9438     0.9154    \n",
            "36       0.000181   0.5107     0.9621     0.9264     0.9416     0.9139    \n",
            "41       0.000078   0.5093     0.9638     0.9320     0.9461     0.9194    \n",
            "46       0.000016   0.5084     0.9633     0.9305     0.9456     0.9172    \n",
            "50       0.000000   0.5087     0.9638     0.9314     0.9466     0.9181    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9657 | F1: 0.9319 | Prec: 0.9423 | Rec: 0.9246\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.38ms\n",
            "\n",
            "Generating t-SNE plot for MOBIACT - Full Model (Ours)...\n",
            "\n",
            "============================================================\n",
            "Training MOBIACT - w/o Physics Priors\n",
            "============================================================\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 1.17ms\n",
            "Input: (9, 100) | Classes: 9\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        0.000999   1.3990     0.6943     0.3732     0.6816     0.3889     (*)\n",
            "6        0.000965   0.6413     0.9453     0.8850     0.8965     0.8764     (*)\n",
            "11       0.000885   0.5657     0.9503     0.8950     0.9155     0.8808    \n",
            "16       0.000768   0.5359     0.9597     0.9198     0.9340     0.9080     (*)\n",
            "21       0.000624   0.5255     0.9608     0.9242     0.9383     0.9129    \n",
            "26       0.000469   0.5157     0.9595     0.9252     0.9413     0.9110    \n",
            "31       0.000316   0.5140     0.9606     0.9245     0.9386     0.9134    \n",
            "36       0.000181   0.5098     0.9627     0.9294     0.9415     0.9188    \n",
            "41       0.000078   0.5086     0.9623     0.9291     0.9429     0.9168    \n",
            "46       0.000016   0.5079     0.9629     0.9302     0.9437     0.9184    \n",
            "50       0.000000   0.5073     0.9631     0.9306     0.9436     0.9192    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9633 | F1: 0.9318 | Prec: 0.9435 | Rec: 0.9215\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 1.17ms\n",
            "\n",
            "Generating t-SNE plot for MOBIACT - w/o Physics Priors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MOBIACT - Fixed Physics\n",
            "============================================================\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.30ms\n",
            "Input: (9, 100) | Classes: 9\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.4452     0.6890     0.3062     0.5282     0.3716     (*)\n",
            "6        0.000965   0.6427     0.9466     0.8859     0.9042     0.8757     (*)\n",
            "11       0.000885   0.5665     0.9524     0.9029     0.9205     0.8924    \n",
            "16       0.000768   0.5401     0.9593     0.9209     0.9279     0.9152    \n",
            "21       0.000624   0.5255     0.9653     0.9357     0.9490     0.9240    \n",
            "26       0.000469   0.5171     0.9610     0.9291     0.9437     0.9157    \n",
            "31       0.000316   0.5126     0.9601     0.9256     0.9394     0.9133    \n",
            "36       0.000181   0.5096     0.9631     0.9316     0.9445     0.9206    \n",
            "41       0.000078   0.5077     0.9631     0.9321     0.9440     0.9216    \n",
            "46       0.000016   0.5072     0.9627     0.9311     0.9430     0.9209    \n",
            "50       0.000000   0.5073     0.9627     0.9312     0.9434     0.9207    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9659 | F1: 0.9343 | Prec: 0.9455 | Rec: 0.9249\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.30ms\n",
            "\n",
            "Generating t-SNE plot for MOBIACT - Fixed Physics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MOBIACT - w/o Physics Gradient\n",
            "============================================================\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.02ms\n",
            "Input: (9, 100) | Classes: 9\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.4410     0.6890     0.3490     0.5027     0.3667     (*)\n",
            "6        0.000965   0.6327     0.9486     0.8895     0.9022     0.8805     (*)\n",
            "11       0.000885   0.5657     0.9505     0.9029     0.9213     0.8891    \n",
            "16       0.000768   0.5394     0.9569     0.9171     0.9375     0.9012    \n",
            "21       0.000624   0.5267     0.9616     0.9267     0.9448     0.9120    \n",
            "26       0.000469   0.5191     0.9651     0.9289     0.9403     0.9196    \n",
            "31       0.000316   0.5120     0.9631     0.9286     0.9442     0.9148    \n",
            "36       0.000181   0.5104     0.9644     0.9308     0.9446     0.9195    \n",
            "41       0.000078   0.5091     0.9640     0.9311     0.9463     0.9186    \n",
            "46       0.000016   0.5077     0.9640     0.9303     0.9447     0.9182    \n",
            "50       0.000000   0.5076     0.9631     0.9290     0.9437     0.9164    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9670 | F1: 0.9311 | Prec: 0.9375 | Rec: 0.9249\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.02ms\n",
            "\n",
            "Generating t-SNE plot for MOBIACT - w/o Physics Gradient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 1177, in <cell line: 0>\n",
            "    result = train_single_dataset(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 976, in train_single_dataset\n",
            "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 929, in compute_flops_params\n",
            "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thop/profile.py\", line 212, in profile\n",
            "    model(*inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 787, in forward\n",
            "    landscape_features = self.landscape_encoder(energy, gradient, x)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 758, in forward\n",
            "    x = self.encoder(landscape_state.transpose(1, 2))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\", line 229, in forward\n",
            "    return F.layer_norm(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2901, in layer_norm\n",
            "    return torch.layer_norm(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error training MOBIACT with w/o Landscape Enc: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 9]\n",
            "\n",
            "============================================================\n",
            "Training MOBIACT - w/o Energy Loss\n",
            "============================================================\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.46ms\n",
            "Input: (9, 100) | Classes: 9\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.4344     0.6549     0.2633     0.4503     0.3115     (*)\n",
            "6        0.000965   0.6398     0.9357     0.8652     0.8979     0.8508     (*)\n",
            "11       0.000885   0.5643     0.9561     0.8998     0.9188     0.8915    \n",
            "16       0.000768   0.5310     0.9633     0.9261     0.9377     0.9158    \n",
            "21       0.000624   0.5181     0.9636     0.9291     0.9367     0.9226    \n",
            "26       0.000469   0.5127     0.9636     0.9282     0.9421     0.9166    \n",
            "31       0.000316   0.5057     0.9625     0.9272     0.9398     0.9161    \n",
            "36       0.000181   0.5049     0.9659     0.9347     0.9461     0.9247     (*)\n",
            "41       0.000078   0.5032     0.9640     0.9328     0.9453     0.9218    \n",
            "46       0.000016   0.5030     0.9646     0.9335     0.9459     0.9225    \n",
            "50       0.000000   0.5029     0.9646     0.9341     0.9463     0.9233    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9659 | F1: 0.9347 | Prec: 0.9461 | Rec: 0.9247\n",
            "Params: 0.20M | FLOPs: 3.31M | Inf: 2.46ms\n",
            "\n",
            "Generating t-SNE plot for MOBIACT - w/o Energy Loss...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MOTIONSENSE - Full Model (Ours)\n",
            "============================================================\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 2.42ms\n",
            "Input: (12, 128) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   0.9357     0.8947     0.8401     0.8706     0.8448     (*)\n",
            "6        0.000965   0.4756     0.9543     0.9260     0.9185     0.9419    \n",
            "11       0.000885   0.4488     0.9353     0.9087     0.8942     0.9336    \n",
            "16       0.000768   0.4390     0.9421     0.9227     0.9096     0.9408    \n",
            "21       0.000624   0.4366     0.9401     0.9190     0.9074     0.9346    \n",
            "26       0.000469   0.4352     0.9417     0.9232     0.9113     0.9399    \n",
            "31       0.000316   0.4336     0.9410     0.9216     0.9104     0.9376    \n",
            "36       0.000181   0.4331     0.9397     0.9182     0.9058     0.9372    \n",
            "41       0.000078   0.4328     0.9408     0.9208     0.9084     0.9386    \n",
            "46       0.000016   0.4325     0.9404     0.9196     0.9072     0.9376    \n",
            "50       0.000000   0.4325     0.9401     0.9197     0.9076     0.9376    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9590 | F1: 0.9334 | Prec: 0.9246 | Rec: 0.9474\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 2.42ms\n",
            "\n",
            "Generating t-SNE plot for MOTIONSENSE - Full Model (Ours)...\n",
            "\n",
            "============================================================\n",
            "Training MOTIONSENSE - w/o Physics Priors\n",
            "============================================================\n",
            "Params: 0.22M | FLOPs: 4.82M | Inf: 1.12ms\n",
            "Input: (12, 128) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        0.000999   1.0449     0.8894     0.8286     0.8608     0.8435     (*)\n",
            "6        0.000965   0.4741     0.9428     0.9237     0.9106     0.9421    \n",
            "11       0.000885   0.4499     0.9446     0.9229     0.9085     0.9417    \n",
            "16       0.000768   0.4384     0.9457     0.9257     0.9117     0.9447    \n",
            "21       0.000624   0.4367     0.9404     0.9189     0.9063     0.9379    \n",
            "26       0.000469   0.4343     0.9419     0.9191     0.9062     0.9381    \n",
            "31       0.000316   0.4329     0.9399     0.9160     0.9025     0.9374    \n",
            "36       0.000181   0.4325     0.9406     0.9177     0.9057     0.9365    \n",
            "41       0.000078   0.4323     0.9401     0.9169     0.9040     0.9367    \n",
            "46       0.000016   0.4320     0.9410     0.9176     0.9044     0.9373    \n",
            "50       0.000000   0.4319     0.9408     0.9173     0.9043     0.9371    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9517 | F1: 0.9286 | Prec: 0.9139 | Rec: 0.9480\n",
            "Params: 0.22M | FLOPs: 4.82M | Inf: 1.12ms\n",
            "\n",
            "Generating t-SNE plot for MOTIONSENSE - w/o Physics Priors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MOTIONSENSE - Fixed Physics\n",
            "============================================================\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 2.47ms\n",
            "Input: (12, 128) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   1.0443     0.8918     0.8300     0.8519     0.8594     (*)\n",
            "6        0.000965   0.4766     0.9525     0.9305     0.9202     0.9458     (*)\n",
            "11       0.000885   0.4468     0.9426     0.9234     0.9107     0.9429    \n",
            "16       0.000768   0.4396     0.9370     0.9132     0.8983     0.9365    \n",
            "21       0.000624   0.4366     0.9384     0.9152     0.9017     0.9361    \n",
            "26       0.000469   0.4348     0.9386     0.9136     0.9010     0.9334    \n",
            "31       0.000316   0.4337     0.9366     0.9112     0.8975     0.9338    \n",
            "36       0.000181   0.4330     0.9373     0.9122     0.8994     0.9322    \n",
            "41       0.000078   0.4326     0.9375     0.9130     0.8997     0.9345    \n",
            "46       0.000016   0.4326     0.9370     0.9117     0.8978     0.9332    \n",
            "50       0.000000   0.4324     0.9373     0.9126     0.8993     0.9336    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9525 | F1: 0.9305 | Prec: 0.9202 | Rec: 0.9458\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 2.47ms\n",
            "\n",
            "Generating t-SNE plot for MOTIONSENSE - Fixed Physics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training MOTIONSENSE - w/o Physics Gradient\n",
            "============================================================\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 3.18ms\n",
            "Input: (12, 128) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   0.9528     0.9060     0.8635     0.8894     0.8650     (*)\n",
            "6        0.000965   0.4734     0.9510     0.9272     0.9134     0.9454    \n",
            "11       0.000885   0.4489     0.9432     0.9209     0.9053     0.9433    \n",
            "16       0.000768   0.4383     0.9421     0.9210     0.9066     0.9417    \n",
            "21       0.000624   0.4357     0.9404     0.9180     0.9032     0.9397    \n",
            "26       0.000469   0.4357     0.9341     0.9099     0.8984     0.9313    \n",
            "31       0.000316   0.4334     0.9390     0.9146     0.9016     0.9365    \n",
            "36       0.000181   0.4327     0.9397     0.9174     0.9035     0.9376    \n",
            "41       0.000078   0.4323     0.9388     0.9152     0.9014     0.9366    \n",
            "46       0.000016   0.4323     0.9381     0.9129     0.8990     0.9353    \n",
            "50       0.000000   0.4322     0.9377     0.9128     0.8991     0.9351    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9557 | F1: 0.9264 | Prec: 0.9077 | Rec: 0.9521\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 3.18ms\n",
            "\n",
            "Generating t-SNE plot for MOTIONSENSE - w/o Physics Gradient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 1177, in <cell line: 0>\n",
            "    result = train_single_dataset(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 976, in train_single_dataset\n",
            "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 929, in compute_flops_params\n",
            "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thop/profile.py\", line 212, in profile\n",
            "    model(*inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 787, in forward\n",
            "    landscape_features = self.landscape_encoder(energy, gradient, x)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 758, in forward\n",
            "    x = self.encoder(landscape_state.transpose(1, 2))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\", line 229, in forward\n",
            "    return F.layer_norm(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2901, in layer_norm\n",
            "    return torch.layer_norm(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error training MOTIONSENSE with w/o Landscape Enc: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 12]\n",
            "\n",
            "============================================================\n",
            "Training MOTIONSENSE - w/o Energy Loss\n",
            "============================================================\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 2.36ms\n",
            "Input: (12, 128) | Classes: 6\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   0.9777     0.8636     0.7988     0.8710     0.8065     (*)\n",
            "6        0.000965   0.4696     0.9621     0.9347     0.9223     0.9536     (*)\n",
            "11       0.000885   0.4435     0.9408     0.9081     0.8985     0.9291    \n",
            "16       0.000768   0.4365     0.9470     0.9186     0.9029     0.9431    \n",
            "21       0.000624   0.4322     0.9545     0.9247     0.9111     0.9475    \n",
            "26       0.000469   0.4307     0.9514     0.9264     0.9132     0.9472    \n",
            "31       0.000316   0.4297     0.9552     0.9292     0.9166     0.9484    \n",
            "36       0.000181   0.4292     0.9596     0.9323     0.9196     0.9515    \n",
            "41       0.000078   0.4291     0.9596     0.9321     0.9193     0.9517    \n",
            "46       0.000016   0.4291     0.9599     0.9324     0.9197     0.9518    \n",
            "50       0.000000   0.4290     0.9592     0.9313     0.9187     0.9510    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.9621 | F1: 0.9347 | Prec: 0.9223 | Rec: 0.9536\n",
            "Params: 0.22M | FLOPs: 4.83M | Inf: 2.36ms\n",
            "\n",
            "Generating t-SNE plot for MOTIONSENSE - w/o Energy Loss...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UNIMIB - Full Model (Ours)\n",
            "============================================================\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 2.10ms\n",
            "Input: (3, 151) | Classes: 17\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   2.3612     0.4456     0.2594     0.4079     0.2969     (*)\n",
            "6        0.000965   1.1533     0.7625     0.6622     0.6908     0.6568     (*)\n",
            "11       0.000885   0.9019     0.8186     0.7533     0.7690     0.7457     (*)\n",
            "16       0.000768   0.7854     0.8386     0.7848     0.8003     0.7789    \n",
            "21       0.000624   0.7146     0.8403     0.7884     0.8050     0.7785    \n",
            "26       0.000469   0.6835     0.8568     0.8112     0.8229     0.8036     (*)\n",
            "31       0.000316   0.6634     0.8449     0.7943     0.8063     0.7861    \n",
            "36       0.000181   0.6514     0.8560     0.8089     0.8239     0.7988    \n",
            "41       0.000078   0.6459     0.8530     0.8071     0.8229     0.7967    \n",
            "46       0.000016   0.6427     0.8534     0.8050     0.8193     0.7951    \n",
            "50       0.000000   0.6432     0.8551     0.8071     0.8217     0.7974    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.8581 | F1: 0.8107 | Prec: 0.8227 | Rec: 0.8021\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 2.10ms\n",
            "\n",
            "Generating t-SNE plot for UNIMIB - Full Model (Ours)...\n",
            "\n",
            "============================================================\n",
            "Training UNIMIB - w/o Physics Priors\n",
            "============================================================\n",
            "Params: 0.23M | FLOPs: 1.32M | Inf: 1.12ms\n",
            "Input: (3, 151) | Classes: 17\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        0.000999   2.3459     0.4677     0.2774     0.2821     0.3172     (*)\n",
            "6        0.000965   1.1654     0.7736     0.6740     0.6947     0.6740     (*)\n",
            "11       0.000885   0.9095     0.8144     0.7393     0.7553     0.7351    \n",
            "16       0.000768   0.7937     0.8398     0.7823     0.7953     0.7757     (*)\n",
            "21       0.000624   0.7200     0.8343     0.7834     0.7929     0.7769    \n",
            "26       0.000469   0.6865     0.8445     0.7914     0.8027     0.7849    \n",
            "31       0.000316   0.6633     0.8398     0.7923     0.8059     0.7834    \n",
            "36       0.000181   0.6512     0.8398     0.7890     0.7985     0.7820    \n",
            "41       0.000078   0.6464     0.8360     0.7856     0.7985     0.7784    \n",
            "46       0.000016   0.6420     0.8398     0.7887     0.8002     0.7821    \n",
            "50       0.000000   0.6421     0.8403     0.7903     0.8024     0.7834    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.8466 | F1: 0.7969 | Prec: 0.8062 | Rec: 0.7916\n",
            "Params: 0.23M | FLOPs: 1.32M | Inf: 1.12ms\n",
            "\n",
            "Generating t-SNE plot for UNIMIB - w/o Physics Priors...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UNIMIB - Fixed Physics\n",
            "============================================================\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 2.06ms\n",
            "Input: (3, 151) | Classes: 17\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   2.3244     0.4703     0.2942     0.3532     0.3208     (*)\n",
            "6        0.000965   1.1486     0.7723     0.6684     0.6872     0.6677     (*)\n",
            "11       0.000885   0.9073     0.8246     0.7611     0.7731     0.7549     (*)\n",
            "16       0.000768   0.7720     0.8318     0.7686     0.7823     0.7720    \n",
            "21       0.000624   0.7146     0.8441     0.7937     0.8079     0.7866    \n",
            "26       0.000469   0.6793     0.8466     0.7971     0.8053     0.7933    \n",
            "31       0.000316   0.6588     0.8483     0.8005     0.8130     0.7932    \n",
            "36       0.000181   0.6498     0.8505     0.8027     0.8125     0.7971     (*)\n",
            "41       0.000078   0.6439     0.8479     0.7987     0.8071     0.7945    \n",
            "46       0.000016   0.6405     0.8488     0.8011     0.8120     0.7952    \n",
            "50       0.000000   0.6401     0.8483     0.8006     0.8110     0.7948    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.8522 | F1: 0.8042 | Prec: 0.8144 | Rec: 0.7990\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 2.06ms\n",
            "\n",
            "Generating t-SNE plot for UNIMIB - Fixed Physics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training UNIMIB - w/o Physics Gradient\n",
            "============================================================\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 1.79ms\n",
            "Input: (3, 151) | Classes: 17\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   2.2926     0.4690     0.2887     0.3678     0.3163     (*)\n",
            "6        0.000965   1.1520     0.7732     0.6737     0.6890     0.6733     (*)\n",
            "11       0.000885   0.9125     0.8161     0.7498     0.7696     0.7423    \n",
            "16       0.000768   0.7799     0.8322     0.7796     0.7908     0.7746    \n",
            "21       0.000624   0.7229     0.8364     0.7847     0.8056     0.7759    \n",
            "26       0.000469   0.6833     0.8483     0.7982     0.8109     0.7917    \n",
            "31       0.000316   0.6632     0.8471     0.7979     0.8096     0.7905    \n",
            "36       0.000181   0.6507     0.8522     0.8087     0.8219     0.8002    \n",
            "41       0.000078   0.6451     0.8530     0.8066     0.8190     0.7984    \n",
            "46       0.000016   0.6422     0.8509     0.8057     0.8204     0.7957    \n",
            "50       0.000000   0.6421     0.8534     0.8076     0.8221     0.7983    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.8573 | F1: 0.8127 | Prec: 0.8255 | Rec: 0.8050\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 1.79ms\n",
            "\n",
            "Generating t-SNE plot for UNIMIB - w/o Physics Gradient...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 1177, in <cell line: 0>\n",
            "    result = train_single_dataset(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 976, in train_single_dataset\n",
            "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 929, in compute_flops_params\n",
            "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/thop/profile.py\", line 212, in profile\n",
            "    model(*inputs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 787, in forward\n",
            "    landscape_features = self.landscape_encoder(energy, gradient, x)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3891870173.py\", line 758, in forward\n",
            "    x = self.encoder(landscape_state.transpose(1, 2))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1881, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1829, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\", line 229, in forward\n",
            "    return F.layer_norm(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2901, in layer_norm\n",
            "    return torch.layer_norm(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error training UNIMIB with w/o Landscape Enc: Given normalized_shape=[128], expected input with shape [*, 128], but got input of size[1, 128, 3]\n",
            "\n",
            "============================================================\n",
            "Training UNIMIB - w/o Energy Loss\n",
            "============================================================\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 2.23ms\n",
            "Input: (3, 151) | Classes: 17\n",
            "Epoch    LR         Loss       Acc        F1         Prec       Rec       \n",
            "------------------------------------------------------------\n",
            "1        0.000999   2.3434     0.4312     0.2164     0.3135     0.2674     (*)\n",
            "6        0.000965   1.1474     0.7638     0.6604     0.6766     0.6575     (*)\n",
            "11       0.000885   0.9022     0.8186     0.7528     0.7688     0.7460     (*)\n",
            "16       0.000768   0.7706     0.8258     0.7629     0.7777     0.7550    \n",
            "21       0.000624   0.7056     0.8322     0.7808     0.7923     0.7743    \n",
            "26       0.000469   0.6739     0.8407     0.7942     0.8043     0.7895    \n",
            "31       0.000316   0.6552     0.8445     0.7982     0.8098     0.7907     (*)\n",
            "36       0.000181   0.6448     0.8407     0.7930     0.8036     0.7870    \n",
            "41       0.000078   0.6383     0.8449     0.7980     0.8085     0.7912    \n",
            "46       0.000016   0.6384     0.8437     0.7979     0.8083     0.7917    \n",
            "50       0.000000   0.6357     0.8437     0.7972     0.8080     0.7905    \n",
            "------------------------------------------------------------\n",
            "Best - Acc: 0.8458 | F1: 0.7988 | Prec: 0.8099 | Rec: 0.7920\n",
            "Params: 0.23M | FLOPs: 1.33M | Inf: 2.23ms\n",
            "\n",
            "Generating t-SNE plot for UNIMIB - w/o Energy Loss...\n",
            "\n",
            "================================================================================\n",
            "FINAL RESULTS - ABLATION STUDY\n",
            "================================================================================\n",
            "\n",
            "    Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            "    UCI-HAR    Full Model (Ours)       0.14     31.69     2.33 0.9325 0.9320 0.9328 0.9327\n",
            "    UCI-HAR   w/o Physics Priors       0.14     31.62     1.43 0.9505 0.9501 0.9519 0.9503\n",
            "    UCI-HAR        Fixed Physics       0.14     31.69     2.34 0.9477 0.9479 0.9489 0.9478\n",
            "    UCI-HAR w/o Physics Gradient       0.14     31.69     1.98 0.9481 0.9477 0.9493 0.9479\n",
            "    UCI-HAR    w/o Landscape Enc       0.15     34.31     2.02 0.9671 0.9677 0.9695 0.9675\n",
            "    UCI-HAR      w/o Energy Loss       0.14     31.69     2.30 0.9481 0.9486 0.9490 0.9492\n",
            "      WISDM    Full Model (Ours)       0.14     19.20     2.05 0.9936 0.9904 0.9903 0.9905\n",
            "      WISDM   w/o Physics Priors       0.14     19.16     1.13 0.9933 0.9895 0.9893 0.9898\n",
            "      WISDM        Fixed Physics       0.14     19.20     2.87 0.9939 0.9904 0.9909 0.9899\n",
            "      WISDM w/o Physics Gradient       0.14     19.20     1.76 0.9929 0.9894 0.9900 0.9888\n",
            "      WISDM      w/o Energy Loss       0.14     19.20     2.06 0.9934 0.9894 0.9892 0.9896\n",
            "     PAMAP2    Full Model (Ours)       0.15     25.92     2.22 0.9664 0.9654 0.9677 0.9633\n",
            "     PAMAP2   w/o Physics Priors       0.15     25.87     1.20 0.9652 0.9640 0.9672 0.9612\n",
            "     PAMAP2        Fixed Physics       0.15     25.92     2.37 0.9683 0.9670 0.9696 0.9646\n",
            "     PAMAP2 w/o Physics Gradient       0.15     25.92     2.01 0.9625 0.9616 0.9652 0.9583\n",
            "     PAMAP2      w/o Energy Loss       0.15     25.92     2.29 0.9638 0.9625 0.9652 0.9601\n",
            "    MHEALTH    Full Model (Ours)       0.15     13.17     2.21 0.9968 0.9970 0.9970 0.9970\n",
            "    MHEALTH   w/o Physics Priors       0.15     13.14     1.12 0.9976 0.9975 0.9973 0.9977\n",
            "    MHEALTH        Fixed Physics       0.15     13.17     2.37 0.9978 0.9979 0.9980 0.9979\n",
            "    MHEALTH w/o Physics Gradient       0.15     13.17     2.00 0.9973 0.9972 0.9970 0.9975\n",
            "    MHEALTH      w/o Energy Loss       0.15     13.17     2.48 0.9968 0.9968 0.9966 0.9970\n",
            "    MOBIACT    Full Model (Ours)       0.20      3.31     2.38 0.9657 0.9319 0.9423 0.9246\n",
            "    MOBIACT   w/o Physics Priors       0.20      3.31     1.17 0.9633 0.9318 0.9435 0.9215\n",
            "    MOBIACT        Fixed Physics       0.20      3.31     2.30 0.9659 0.9343 0.9455 0.9249\n",
            "    MOBIACT w/o Physics Gradient       0.20      3.31     2.02 0.9670 0.9311 0.9375 0.9249\n",
            "    MOBIACT      w/o Energy Loss       0.20      3.31     2.46 0.9659 0.9347 0.9461 0.9247\n",
            "MOTIONSENSE    Full Model (Ours)       0.22      4.83     2.42 0.9590 0.9334 0.9246 0.9474\n",
            "MOTIONSENSE   w/o Physics Priors       0.22      4.82     1.12 0.9517 0.9286 0.9139 0.9480\n",
            "MOTIONSENSE        Fixed Physics       0.22      4.83     2.47 0.9525 0.9305 0.9202 0.9458\n",
            "MOTIONSENSE w/o Physics Gradient       0.22      4.83     3.18 0.9557 0.9264 0.9077 0.9521\n",
            "MOTIONSENSE      w/o Energy Loss       0.22      4.83     2.36 0.9621 0.9347 0.9223 0.9536\n",
            "     UNIMIB    Full Model (Ours)       0.23      1.33     2.10 0.8581 0.8107 0.8227 0.8021\n",
            "     UNIMIB   w/o Physics Priors       0.23      1.32     1.12 0.8466 0.7969 0.8062 0.7916\n",
            "     UNIMIB        Fixed Physics       0.23      1.33     2.06 0.8522 0.8042 0.8144 0.7990\n",
            "     UNIMIB w/o Physics Gradient       0.23      1.33     1.79 0.8573 0.8127 0.8255 0.8050\n",
            "     UNIMIB      w/o Energy Loss       0.23      1.33     2.23 0.8458 0.7988 0.8099 0.7920\n",
            "\n",
            "================================================================================\n",
            "\n",
            "UCI-HAR Results:\n",
            "Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            "UCI-HAR    Full Model (Ours)       0.14     31.69     2.33 0.9325 0.9320 0.9328 0.9327\n",
            "UCI-HAR   w/o Physics Priors       0.14     31.62     1.43 0.9505 0.9501 0.9519 0.9503\n",
            "UCI-HAR        Fixed Physics       0.14     31.69     2.34 0.9477 0.9479 0.9489 0.9478\n",
            "UCI-HAR w/o Physics Gradient       0.14     31.69     1.98 0.9481 0.9477 0.9493 0.9479\n",
            "UCI-HAR    w/o Landscape Enc       0.15     34.31     2.02 0.9671 0.9677 0.9695 0.9675\n",
            "UCI-HAR      w/o Energy Loss       0.14     31.69     2.30 0.9481 0.9486 0.9490 0.9492\n",
            "\n",
            "WISDM Results:\n",
            "Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            "  WISDM    Full Model (Ours)       0.14     19.20     2.05 0.9936 0.9904 0.9903 0.9905\n",
            "  WISDM   w/o Physics Priors       0.14     19.16     1.13 0.9933 0.9895 0.9893 0.9898\n",
            "  WISDM        Fixed Physics       0.14     19.20     2.87 0.9939 0.9904 0.9909 0.9899\n",
            "  WISDM w/o Physics Gradient       0.14     19.20     1.76 0.9929 0.9894 0.9900 0.9888\n",
            "  WISDM      w/o Energy Loss       0.14     19.20     2.06 0.9934 0.9894 0.9892 0.9896\n",
            "\n",
            "PAMAP2 Results:\n",
            "Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            " PAMAP2    Full Model (Ours)       0.15     25.92     2.22 0.9664 0.9654 0.9677 0.9633\n",
            " PAMAP2   w/o Physics Priors       0.15     25.87     1.20 0.9652 0.9640 0.9672 0.9612\n",
            " PAMAP2        Fixed Physics       0.15     25.92     2.37 0.9683 0.9670 0.9696 0.9646\n",
            " PAMAP2 w/o Physics Gradient       0.15     25.92     2.01 0.9625 0.9616 0.9652 0.9583\n",
            " PAMAP2      w/o Energy Loss       0.15     25.92     2.29 0.9638 0.9625 0.9652 0.9601\n",
            "\n",
            "MHEALTH Results:\n",
            "Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            "MHEALTH    Full Model (Ours)       0.15     13.17     2.21 0.9968 0.9970 0.9970 0.9970\n",
            "MHEALTH   w/o Physics Priors       0.15     13.14     1.12 0.9976 0.9975 0.9973 0.9977\n",
            "MHEALTH        Fixed Physics       0.15     13.17     2.37 0.9978 0.9979 0.9980 0.9979\n",
            "MHEALTH w/o Physics Gradient       0.15     13.17     2.00 0.9973 0.9972 0.9970 0.9975\n",
            "MHEALTH      w/o Energy Loss       0.15     13.17     2.48 0.9968 0.9968 0.9966 0.9970\n",
            "\n",
            "MOBIACT Results:\n",
            "Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            "MOBIACT    Full Model (Ours)        0.2      3.31     2.38 0.9657 0.9319 0.9423 0.9246\n",
            "MOBIACT   w/o Physics Priors        0.2      3.31     1.17 0.9633 0.9318 0.9435 0.9215\n",
            "MOBIACT        Fixed Physics        0.2      3.31     2.30 0.9659 0.9343 0.9455 0.9249\n",
            "MOBIACT w/o Physics Gradient        0.2      3.31     2.02 0.9670 0.9311 0.9375 0.9249\n",
            "MOBIACT      w/o Energy Loss        0.2      3.31     2.46 0.9659 0.9347 0.9461 0.9247\n",
            "\n",
            "MOTIONSENSE Results:\n",
            "    Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            "MOTIONSENSE    Full Model (Ours)       0.22      4.83     2.42 0.9590 0.9334 0.9246 0.9474\n",
            "MOTIONSENSE   w/o Physics Priors       0.22      4.82     1.12 0.9517 0.9286 0.9139 0.9480\n",
            "MOTIONSENSE        Fixed Physics       0.22      4.83     2.47 0.9525 0.9305 0.9202 0.9458\n",
            "MOTIONSENSE w/o Physics Gradient       0.22      4.83     3.18 0.9557 0.9264 0.9077 0.9521\n",
            "MOTIONSENSE      w/o Energy Loss       0.22      4.83     2.36 0.9621 0.9347 0.9223 0.9536\n",
            "\n",
            "UNIMIB Results:\n",
            "Dataset               Config  Params(M)  FLOPs(M)  Inf(ms)    Acc     F1   Prec    Rec\n",
            " UNIMIB    Full Model (Ours)       0.23      1.33     2.10 0.8581 0.8107 0.8227 0.8021\n",
            " UNIMIB   w/o Physics Priors       0.23      1.32     1.12 0.8466 0.7969 0.8062 0.7916\n",
            " UNIMIB        Fixed Physics       0.23      1.33     2.06 0.8522 0.8042 0.8144 0.7990\n",
            " UNIMIB w/o Physics Gradient       0.23      1.33     1.79 0.8573 0.8127 0.8255 0.8050\n",
            " UNIMIB      w/o Energy Loss       0.23      1.33     2.23 0.8458 0.7988 0.8099 0.7920\n",
            "\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Dataset                Config  Params(M)  FLOPs(M)  Inf(ms)     Acc  \\\n",
              "0       UCI-HAR     Full Model (Ours)       0.14     31.69     2.33  0.9325   \n",
              "1       UCI-HAR    w/o Physics Priors       0.14     31.62     1.43  0.9505   \n",
              "2       UCI-HAR         Fixed Physics       0.14     31.69     2.34  0.9477   \n",
              "3       UCI-HAR  w/o Physics Gradient       0.14     31.69     1.98  0.9481   \n",
              "4       UCI-HAR     w/o Landscape Enc       0.15     34.31     2.02  0.9671   \n",
              "5       UCI-HAR       w/o Energy Loss       0.14     31.69     2.30  0.9481   \n",
              "6         WISDM     Full Model (Ours)       0.14     19.20     2.05  0.9936   \n",
              "7         WISDM    w/o Physics Priors       0.14     19.16     1.13  0.9933   \n",
              "8         WISDM         Fixed Physics       0.14     19.20     2.87  0.9939   \n",
              "9         WISDM  w/o Physics Gradient       0.14     19.20     1.76  0.9929   \n",
              "10        WISDM       w/o Energy Loss       0.14     19.20     2.06  0.9934   \n",
              "11       PAMAP2     Full Model (Ours)       0.15     25.92     2.22  0.9664   \n",
              "12       PAMAP2    w/o Physics Priors       0.15     25.87     1.20  0.9652   \n",
              "13       PAMAP2         Fixed Physics       0.15     25.92     2.37  0.9683   \n",
              "14       PAMAP2  w/o Physics Gradient       0.15     25.92     2.01  0.9625   \n",
              "15       PAMAP2       w/o Energy Loss       0.15     25.92     2.29  0.9638   \n",
              "16      MHEALTH     Full Model (Ours)       0.15     13.17     2.21  0.9968   \n",
              "17      MHEALTH    w/o Physics Priors       0.15     13.14     1.12  0.9976   \n",
              "18      MHEALTH         Fixed Physics       0.15     13.17     2.37  0.9978   \n",
              "19      MHEALTH  w/o Physics Gradient       0.15     13.17     2.00  0.9973   \n",
              "20      MHEALTH       w/o Energy Loss       0.15     13.17     2.48  0.9968   \n",
              "21      MOBIACT     Full Model (Ours)       0.20      3.31     2.38  0.9657   \n",
              "22      MOBIACT    w/o Physics Priors       0.20      3.31     1.17  0.9633   \n",
              "23      MOBIACT         Fixed Physics       0.20      3.31     2.30  0.9659   \n",
              "24      MOBIACT  w/o Physics Gradient       0.20      3.31     2.02  0.9670   \n",
              "25      MOBIACT       w/o Energy Loss       0.20      3.31     2.46  0.9659   \n",
              "26  MOTIONSENSE     Full Model (Ours)       0.22      4.83     2.42  0.9590   \n",
              "27  MOTIONSENSE    w/o Physics Priors       0.22      4.82     1.12  0.9517   \n",
              "28  MOTIONSENSE         Fixed Physics       0.22      4.83     2.47  0.9525   \n",
              "29  MOTIONSENSE  w/o Physics Gradient       0.22      4.83     3.18  0.9557   \n",
              "30  MOTIONSENSE       w/o Energy Loss       0.22      4.83     2.36  0.9621   \n",
              "31       UNIMIB     Full Model (Ours)       0.23      1.33     2.10  0.8581   \n",
              "32       UNIMIB    w/o Physics Priors       0.23      1.32     1.12  0.8466   \n",
              "33       UNIMIB         Fixed Physics       0.23      1.33     2.06  0.8522   \n",
              "34       UNIMIB  w/o Physics Gradient       0.23      1.33     1.79  0.8573   \n",
              "35       UNIMIB       w/o Energy Loss       0.23      1.33     2.23  0.8458   \n",
              "\n",
              "        F1    Prec     Rec  \n",
              "0   0.9320  0.9328  0.9327  \n",
              "1   0.9501  0.9519  0.9503  \n",
              "2   0.9479  0.9489  0.9478  \n",
              "3   0.9477  0.9493  0.9479  \n",
              "4   0.9677  0.9695  0.9675  \n",
              "5   0.9486  0.9490  0.9492  \n",
              "6   0.9904  0.9903  0.9905  \n",
              "7   0.9895  0.9893  0.9898  \n",
              "8   0.9904  0.9909  0.9899  \n",
              "9   0.9894  0.9900  0.9888  \n",
              "10  0.9894  0.9892  0.9896  \n",
              "11  0.9654  0.9677  0.9633  \n",
              "12  0.9640  0.9672  0.9612  \n",
              "13  0.9670  0.9696  0.9646  \n",
              "14  0.9616  0.9652  0.9583  \n",
              "15  0.9625  0.9652  0.9601  \n",
              "16  0.9970  0.9970  0.9970  \n",
              "17  0.9975  0.9973  0.9977  \n",
              "18  0.9979  0.9980  0.9979  \n",
              "19  0.9972  0.9970  0.9975  \n",
              "20  0.9968  0.9966  0.9970  \n",
              "21  0.9319  0.9423  0.9246  \n",
              "22  0.9318  0.9435  0.9215  \n",
              "23  0.9343  0.9455  0.9249  \n",
              "24  0.9311  0.9375  0.9249  \n",
              "25  0.9347  0.9461  0.9247  \n",
              "26  0.9334  0.9246  0.9474  \n",
              "27  0.9286  0.9139  0.9480  \n",
              "28  0.9305  0.9202  0.9458  \n",
              "29  0.9264  0.9077  0.9521  \n",
              "30  0.9347  0.9223  0.9536  \n",
              "31  0.8107  0.8227  0.8021  \n",
              "32  0.7969  0.8062  0.7916  \n",
              "33  0.8042  0.8144  0.7990  \n",
              "34  0.8127  0.8255  0.8050  \n",
              "35  0.7988  0.8099  0.7920  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97bf41f8-ae25-4791-a147-caa4ab3cce31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Config</th>\n",
              "      <th>Params(M)</th>\n",
              "      <th>FLOPs(M)</th>\n",
              "      <th>Inf(ms)</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "      <th>Prec</th>\n",
              "      <th>Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UCI-HAR</td>\n",
              "      <td>Full Model (Ours)</td>\n",
              "      <td>0.14</td>\n",
              "      <td>31.69</td>\n",
              "      <td>2.33</td>\n",
              "      <td>0.9325</td>\n",
              "      <td>0.9320</td>\n",
              "      <td>0.9328</td>\n",
              "      <td>0.9327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UCI-HAR</td>\n",
              "      <td>w/o Physics Priors</td>\n",
              "      <td>0.14</td>\n",
              "      <td>31.62</td>\n",
              "      <td>1.43</td>\n",
              "      <td>0.9505</td>\n",
              "      <td>0.9501</td>\n",
              "      <td>0.9519</td>\n",
              "      <td>0.9503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UCI-HAR</td>\n",
              "      <td>Fixed Physics</td>\n",
              "      <td>0.14</td>\n",
              "      <td>31.69</td>\n",
              "      <td>2.34</td>\n",
              "      <td>0.9477</td>\n",
              "      <td>0.9479</td>\n",
              "      <td>0.9489</td>\n",
              "      <td>0.9478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UCI-HAR</td>\n",
              "      <td>w/o Physics Gradient</td>\n",
              "      <td>0.14</td>\n",
              "      <td>31.69</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.9481</td>\n",
              "      <td>0.9477</td>\n",
              "      <td>0.9493</td>\n",
              "      <td>0.9479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UCI-HAR</td>\n",
              "      <td>w/o Landscape Enc</td>\n",
              "      <td>0.15</td>\n",
              "      <td>34.31</td>\n",
              "      <td>2.02</td>\n",
              "      <td>0.9671</td>\n",
              "      <td>0.9677</td>\n",
              "      <td>0.9695</td>\n",
              "      <td>0.9675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>UCI-HAR</td>\n",
              "      <td>w/o Energy Loss</td>\n",
              "      <td>0.14</td>\n",
              "      <td>31.69</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.9481</td>\n",
              "      <td>0.9486</td>\n",
              "      <td>0.9490</td>\n",
              "      <td>0.9492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WISDM</td>\n",
              "      <td>Full Model (Ours)</td>\n",
              "      <td>0.14</td>\n",
              "      <td>19.20</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.9936</td>\n",
              "      <td>0.9904</td>\n",
              "      <td>0.9903</td>\n",
              "      <td>0.9905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WISDM</td>\n",
              "      <td>w/o Physics Priors</td>\n",
              "      <td>0.14</td>\n",
              "      <td>19.16</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.9933</td>\n",
              "      <td>0.9895</td>\n",
              "      <td>0.9893</td>\n",
              "      <td>0.9898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>WISDM</td>\n",
              "      <td>Fixed Physics</td>\n",
              "      <td>0.14</td>\n",
              "      <td>19.20</td>\n",
              "      <td>2.87</td>\n",
              "      <td>0.9939</td>\n",
              "      <td>0.9904</td>\n",
              "      <td>0.9909</td>\n",
              "      <td>0.9899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>WISDM</td>\n",
              "      <td>w/o Physics Gradient</td>\n",
              "      <td>0.14</td>\n",
              "      <td>19.20</td>\n",
              "      <td>1.76</td>\n",
              "      <td>0.9929</td>\n",
              "      <td>0.9894</td>\n",
              "      <td>0.9900</td>\n",
              "      <td>0.9888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>WISDM</td>\n",
              "      <td>w/o Energy Loss</td>\n",
              "      <td>0.14</td>\n",
              "      <td>19.20</td>\n",
              "      <td>2.06</td>\n",
              "      <td>0.9934</td>\n",
              "      <td>0.9894</td>\n",
              "      <td>0.9892</td>\n",
              "      <td>0.9896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PAMAP2</td>\n",
              "      <td>Full Model (Ours)</td>\n",
              "      <td>0.15</td>\n",
              "      <td>25.92</td>\n",
              "      <td>2.22</td>\n",
              "      <td>0.9664</td>\n",
              "      <td>0.9654</td>\n",
              "      <td>0.9677</td>\n",
              "      <td>0.9633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PAMAP2</td>\n",
              "      <td>w/o Physics Priors</td>\n",
              "      <td>0.15</td>\n",
              "      <td>25.87</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.9652</td>\n",
              "      <td>0.9640</td>\n",
              "      <td>0.9672</td>\n",
              "      <td>0.9612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PAMAP2</td>\n",
              "      <td>Fixed Physics</td>\n",
              "      <td>0.15</td>\n",
              "      <td>25.92</td>\n",
              "      <td>2.37</td>\n",
              "      <td>0.9683</td>\n",
              "      <td>0.9670</td>\n",
              "      <td>0.9696</td>\n",
              "      <td>0.9646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PAMAP2</td>\n",
              "      <td>w/o Physics Gradient</td>\n",
              "      <td>0.15</td>\n",
              "      <td>25.92</td>\n",
              "      <td>2.01</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>0.9616</td>\n",
              "      <td>0.9652</td>\n",
              "      <td>0.9583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PAMAP2</td>\n",
              "      <td>w/o Energy Loss</td>\n",
              "      <td>0.15</td>\n",
              "      <td>25.92</td>\n",
              "      <td>2.29</td>\n",
              "      <td>0.9638</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>0.9652</td>\n",
              "      <td>0.9601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>MHEALTH</td>\n",
              "      <td>Full Model (Ours)</td>\n",
              "      <td>0.15</td>\n",
              "      <td>13.17</td>\n",
              "      <td>2.21</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>0.9970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>MHEALTH</td>\n",
              "      <td>w/o Physics Priors</td>\n",
              "      <td>0.15</td>\n",
              "      <td>13.14</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.9976</td>\n",
              "      <td>0.9975</td>\n",
              "      <td>0.9973</td>\n",
              "      <td>0.9977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>MHEALTH</td>\n",
              "      <td>Fixed Physics</td>\n",
              "      <td>0.15</td>\n",
              "      <td>13.17</td>\n",
              "      <td>2.37</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>0.9979</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>0.9979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>MHEALTH</td>\n",
              "      <td>w/o Physics Gradient</td>\n",
              "      <td>0.15</td>\n",
              "      <td>13.17</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.9973</td>\n",
              "      <td>0.9972</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>0.9975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>MHEALTH</td>\n",
              "      <td>w/o Energy Loss</td>\n",
              "      <td>0.15</td>\n",
              "      <td>13.17</td>\n",
              "      <td>2.48</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>0.9966</td>\n",
              "      <td>0.9970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>MOBIACT</td>\n",
              "      <td>Full Model (Ours)</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.31</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.9657</td>\n",
              "      <td>0.9319</td>\n",
              "      <td>0.9423</td>\n",
              "      <td>0.9246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>MOBIACT</td>\n",
              "      <td>w/o Physics Priors</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.31</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.9633</td>\n",
              "      <td>0.9318</td>\n",
              "      <td>0.9435</td>\n",
              "      <td>0.9215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>MOBIACT</td>\n",
              "      <td>Fixed Physics</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.31</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.9659</td>\n",
              "      <td>0.9343</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.9249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>MOBIACT</td>\n",
              "      <td>w/o Physics Gradient</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.31</td>\n",
              "      <td>2.02</td>\n",
              "      <td>0.9670</td>\n",
              "      <td>0.9311</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.9249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>MOBIACT</td>\n",
              "      <td>w/o Energy Loss</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.31</td>\n",
              "      <td>2.46</td>\n",
              "      <td>0.9659</td>\n",
              "      <td>0.9347</td>\n",
              "      <td>0.9461</td>\n",
              "      <td>0.9247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>MOTIONSENSE</td>\n",
              "      <td>Full Model (Ours)</td>\n",
              "      <td>0.22</td>\n",
              "      <td>4.83</td>\n",
              "      <td>2.42</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.9334</td>\n",
              "      <td>0.9246</td>\n",
              "      <td>0.9474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>MOTIONSENSE</td>\n",
              "      <td>w/o Physics Priors</td>\n",
              "      <td>0.22</td>\n",
              "      <td>4.82</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.9517</td>\n",
              "      <td>0.9286</td>\n",
              "      <td>0.9139</td>\n",
              "      <td>0.9480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>MOTIONSENSE</td>\n",
              "      <td>Fixed Physics</td>\n",
              "      <td>0.22</td>\n",
              "      <td>4.83</td>\n",
              "      <td>2.47</td>\n",
              "      <td>0.9525</td>\n",
              "      <td>0.9305</td>\n",
              "      <td>0.9202</td>\n",
              "      <td>0.9458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>MOTIONSENSE</td>\n",
              "      <td>w/o Physics Gradient</td>\n",
              "      <td>0.22</td>\n",
              "      <td>4.83</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.9557</td>\n",
              "      <td>0.9264</td>\n",
              "      <td>0.9077</td>\n",
              "      <td>0.9521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>MOTIONSENSE</td>\n",
              "      <td>w/o Energy Loss</td>\n",
              "      <td>0.22</td>\n",
              "      <td>4.83</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.9621</td>\n",
              "      <td>0.9347</td>\n",
              "      <td>0.9223</td>\n",
              "      <td>0.9536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>UNIMIB</td>\n",
              "      <td>Full Model (Ours)</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.33</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.8581</td>\n",
              "      <td>0.8107</td>\n",
              "      <td>0.8227</td>\n",
              "      <td>0.8021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>UNIMIB</td>\n",
              "      <td>w/o Physics Priors</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.8466</td>\n",
              "      <td>0.7969</td>\n",
              "      <td>0.8062</td>\n",
              "      <td>0.7916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>UNIMIB</td>\n",
              "      <td>Fixed Physics</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.33</td>\n",
              "      <td>2.06</td>\n",
              "      <td>0.8522</td>\n",
              "      <td>0.8042</td>\n",
              "      <td>0.8144</td>\n",
              "      <td>0.7990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>UNIMIB</td>\n",
              "      <td>w/o Physics Gradient</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.8573</td>\n",
              "      <td>0.8127</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>UNIMIB</td>\n",
              "      <td>w/o Energy Loss</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.33</td>\n",
              "      <td>2.23</td>\n",
              "      <td>0.8458</td>\n",
              "      <td>0.7988</td>\n",
              "      <td>0.8099</td>\n",
              "      <td>0.7920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97bf41f8-ae25-4791-a147-caa4ab3cce31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97bf41f8-ae25-4791-a147-caa4ab3cce31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97bf41f8-ae25-4791-a147-caa4ab3cce31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2758bc6f-3672-44d2-a8ac-00dbe73b8a78\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2758bc6f-3672-44d2-a8ac-00dbe73b8a78')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2758bc6f-3672-44d2-a8ac-00dbe73b8a78 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ab1a4c53-6853-4b48-a80c-b587bde3e83d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab1a4c53-6853-4b48-a80c-b587bde3e83d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 36,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"UCI-HAR\",\n          \"WISDM\",\n          \"MOTIONSENSE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Config\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Full Model (Ours)\",\n          \"w/o Physics Priors\",\n          \"w/o Energy Loss\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Params(M)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03683941988065036,\n        \"min\": 0.14,\n        \"max\": 0.23,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.15,\n          0.23,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLOPs(M)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.459688723299626,\n        \"min\": 1.32,\n        \"max\": 34.31,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          3.31,\n          4.82,\n          31.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inf(ms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5055357051745695,\n        \"min\": 1.12,\n        \"max\": 3.18,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          2.1,\n          2.29,\n          2.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04518694782753372,\n        \"min\": 0.8458,\n        \"max\": 0.9978,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.8573,\n          0.9968,\n          0.9557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05984059214491421,\n        \"min\": 0.7969,\n        \"max\": 0.9979,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.8127,\n          0.9975,\n          0.9305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057074046863673726,\n        \"min\": 0.8062,\n        \"max\": 0.998,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          0.997,\n          0.9423,\n          0.9077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06211872324652026,\n        \"min\": 0.7916,\n        \"max\": 0.9979,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          0.9601,\n          0.9975,\n          0.9521\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install thop ptflops\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "from thop import profile\n",
        "from collections import Counter\n",
        "from glob import glob\n",
        "import glob as glob_module\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "from IPython.display import display\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def clean_state_dict(state_dict):\n",
        "    return {k: v for k, v in state_dict.items()\n",
        "            if 'total_ops' not in k and 'total_params' not in k}\n",
        "\n",
        "\n",
        "class UCIHARDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def read_txt_matrix(file_path):\n",
        "    return np.loadtxt(file_path)\n",
        "\n",
        "\n",
        "def load_uci_har(root_path='/content/drive/MyDrive/HAR_Dataset/UCI'):\n",
        "    print(f\"\\n[UCI-HAR] Loading from: {root_path}\")\n",
        "    UCI_CHANNELS_PREFIX = [\n",
        "        \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\",\n",
        "        \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
        "        \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
        "    ]\n",
        "    def load_split(split):\n",
        "        channels = []\n",
        "        for idx, prefix in enumerate(UCI_CHANNELS_PREFIX):\n",
        "            file_path = os.path.join(root_path, f\"{prefix}{split}.txt\")\n",
        "            print(f\"  [{idx+1}/{len(UCI_CHANNELS_PREFIX)}] Loading: {os.path.basename(file_path)}\")\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "            channels.append(read_txt_matrix(file_path))\n",
        "        X = np.stack(channels, axis=1)\n",
        "        y = read_txt_matrix(os.path.join(root_path, f\"y_{split}.txt\")).astype(int) - 1\n",
        "        return X, y\n",
        "    X_train, y_train = load_split('train')\n",
        "    X_test, y_test = load_split('test')\n",
        "    X_train = X_train.transpose(0, 2, 1)\n",
        "    X_test = X_test.transpose(0, 2, 1)\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_flat)\n",
        "    X_train_flat = scaler.transform(X_train_flat)\n",
        "    X_test_flat = scaler.transform(X_test_flat)\n",
        "    X_train = X_train_flat.reshape(X_train.shape)\n",
        "    X_test = X_test_flat.reshape(X_test.shape)\n",
        "    activity_names = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train.astype(np.int64), X_test, y_test.astype(np.int64), activity_names\n",
        "\n",
        "\n",
        "def load_wisdm_data(dataset_path=\"/content/drive/MyDrive/HAR_Dataset/WISDM\"):\n",
        "    print(f\"\\n[WISDM] Loading from: {dataset_path}\")\n",
        "    if os.path.isfile(dataset_path):\n",
        "        file_paths = [dataset_path]\n",
        "    else:\n",
        "        possible_files = ['WISDM_ar_v1.1_raw.txt', 'WISDM_ar_v1.1_trans.arff', 'wisdm-dataset.txt', 'actitracker_raw.txt']\n",
        "        file_paths = []\n",
        "        for filename in possible_files:\n",
        "            full_path = os.path.join(dataset_path, filename)\n",
        "            if os.path.exists(full_path):\n",
        "                file_paths.append(full_path)\n",
        "                print(f\"  Found: {filename}\")\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "    all_data = []\n",
        "    for idx, file_path in enumerate(file_paths):\n",
        "        print(f\"  [{idx+1}/{len(file_paths)}] Processing: {os.path.basename(file_path)}\")\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        cleaned_data = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            line = line.rstrip(';').rstrip(',')\n",
        "            if ',' in line:\n",
        "                parts = line.split(',')\n",
        "            elif ';' in line:\n",
        "                parts = line.split(';')\n",
        "            else:\n",
        "                continue\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "            try:\n",
        "                user = parts[0].strip()\n",
        "                activity = parts[1].strip()\n",
        "                timestamp = parts[2].strip()\n",
        "                x_str = parts[3].strip()\n",
        "                y_str = parts[4].strip()\n",
        "                z_str = parts[5].strip()\n",
        "                if ';' in x_str:\n",
        "                    x_str = x_str.split(';')[0]\n",
        "                if ';' in y_str:\n",
        "                    y_str = y_str.split(';')[0]\n",
        "                if ';' in z_str:\n",
        "                    z_str = z_str.split(';')[0]\n",
        "                x = float(x_str)\n",
        "                y = float(y_str)\n",
        "                z = float(z_str)\n",
        "                cleaned_data.append([user, activity, timestamp, x, y, z])\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "        if cleaned_data:\n",
        "            df = pd.DataFrame(cleaned_data, columns=['user', 'activity', 'timestamp', 'x', 'y', 'z'])\n",
        "            df['x'] = pd.to_numeric(df['x'], errors='coerce')\n",
        "            df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
        "            df['z'] = pd.to_numeric(df['z'], errors='coerce')\n",
        "            df = df.dropna()\n",
        "            all_data.append(df)\n",
        "    if not all_data:\n",
        "        return None, None, None, None, None\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    combined_df = combined_df.dropna()\n",
        "    combined_df = combined_df[combined_df['activity'].str.strip() != '']\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    groups = combined_df.groupby(['user', 'activity']) if 'user' in combined_df.columns else combined_df.groupby(['activity'])\n",
        "    window_size = 80\n",
        "    step = 40\n",
        "    for group_name, group_data in groups:\n",
        "        activity = group_name[-1] if isinstance(group_name, tuple) else group_name\n",
        "        acc_data = group_data[['x', 'y', 'z']].values.astype(np.float32)\n",
        "        if len(acc_data) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(acc_data):\n",
        "            window_data = acc_data[start:start + window_size, :]\n",
        "            all_windows.append(window_data)\n",
        "            all_labels.append(activity)\n",
        "            start += step\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    class_names = [str(label) for label in label_encoder.classes_]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, class_names\n",
        "\n",
        "\n",
        "def load_dsads_data(data_path, w_s=25, stride=12):\n",
        "    print(f\"\\n[DSADS] Loading from: {data_path}\")\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    activities = {\n",
        "        'a01': 'sitting', 'a02': 'standing', 'a03': 'lying on back',\n",
        "        'a04': 'lying on right side', 'a05': 'ascending stairs',\n",
        "        'a06': 'descending stairs', 'a07': 'standing in an elevator still',\n",
        "        'a08': 'moving around in an elevator', 'a09': 'walking in a parking lot',\n",
        "        'a10': 'walking on a treadmill with a speed of 4 kmh',\n",
        "        'a11': 'walking in flat and 15 deg inclined positions',\n",
        "        'a12': 'running on a treadmill with a speed of 8 kmh',\n",
        "        'a13': 'exercising on a stepper', 'a14': 'exercising on a cross trainer',\n",
        "        'a15': 'cycling on an exercise bike in horizontal positions',\n",
        "        'a16': 'cycling on an exercise bike in vertical positions',\n",
        "        'a17': 'rowing', 'a18': 'jumping', 'a19': 'playing basketball'\n",
        "    }\n",
        "    activity_codes = sorted(activities.keys())\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(activity_codes)\n",
        "    persons = ['p' + str(i) for i in range(1, 9)]\n",
        "    total_activities = len(activity_codes) * len(persons)\n",
        "    progress = 0\n",
        "    for person_str in persons:\n",
        "        for activity_str in activity_codes:\n",
        "            progress += 1\n",
        "            print(f\"  [{progress}/{total_activities}] Processing: {person_str} - {activity_str}\")\n",
        "            activity_label = label_encoder.transform([activity_str])[0]\n",
        "            pattern = os.path.join(data_path, activity_str, person_str, 's*.txt')\n",
        "            segment_files = sorted(glob(pattern))\n",
        "            if not segment_files:\n",
        "                continue\n",
        "            for f in segment_files[:11]:\n",
        "                try:\n",
        "                    segment_data = np.loadtxt(f, delimiter=',')\n",
        "                    if segment_data.shape[0] < w_s or segment_data.shape[1] < 45:\n",
        "                        continue\n",
        "                    segment_data = np.nan_to_num(segment_data, nan=0.0)\n",
        "                    start = 0\n",
        "                    while start + w_s <= segment_data.shape[0]:\n",
        "                        window_data = segment_data[start : start + w_s, :]\n",
        "                        all_windows.append(window_data)\n",
        "                        all_labels.append(activity_label)\n",
        "                        start += stride\n",
        "                except:\n",
        "                    continue\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    scaler = StandardScaler()\n",
        "    X_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_flat = scaler.fit_transform(X_flat)\n",
        "    X_windowed = X_flat.reshape(X_windowed.shape)\n",
        "    activity_names_sorted = [activities[code] for code in label_encoder.classes_]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_names_sorted\n",
        "\n",
        "\n",
        "def load_pamap2_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/PAMAP2\"):\n",
        "    print(f\"\\n[PAMAP2] Loading from: {dataset_dir}\")\n",
        "    file_paths = sorted(glob(os.path.join(dataset_dir, 'Protocol', 'subject*.dat')))\n",
        "    optional_path = os.path.join(dataset_dir, 'Optional')\n",
        "    if os.path.exists(optional_path):\n",
        "        file_paths += sorted(glob(os.path.join(optional_path, 'subject*.dat')))\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "    print(f\"  Found {len(file_paths)} subject files\")\n",
        "    activity_labels = [\n",
        "        \"lying\", \"sitting\", \"standing\", \"walking\", \"running\", \"cycling\",\n",
        "        \"Nordic walking\", \"ascending stairs\", \"descending stairs\",\n",
        "        \"vacuum cleaning\", \"ironing\", \"rope jumping\"\n",
        "    ]\n",
        "    label_to_activity_idx = {\n",
        "        1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 12: 7, 13: 8, 16: 9, 17: 10, 24: 11\n",
        "    }\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 100\n",
        "    step = 50\n",
        "    for idx, file_path in enumerate(file_paths):\n",
        "        print(f\"  [{idx+1}/{len(file_paths)}] Processing: {os.path.basename(file_path)}\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, na_values='NaN')\n",
        "        except:\n",
        "            continue\n",
        "        df_cleaned = df.ffill().bfill()\n",
        "        if df_cleaned.empty:\n",
        "            continue\n",
        "        labels = df_cleaned.iloc[:, 1].values.astype(int)\n",
        "        all_sensor_cols = list(range(4, 10)) + list(range(21, 27)) + list(range(38, 44))\n",
        "        if df_cleaned.shape[1] < max(all_sensor_cols) + 1:\n",
        "            continue\n",
        "        features = df_cleaned.iloc[:, all_sensor_cols].values.astype(np.float32)\n",
        "        valid_indices = np.where(np.isin(labels, list(label_to_activity_idx.keys())))[0]\n",
        "        if len(valid_indices) == 0:\n",
        "            continue\n",
        "        features = features[valid_indices, :]\n",
        "        labels = labels[valid_indices]\n",
        "        if len(features) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(features):\n",
        "            window_data = features[start : start + window_size, :]\n",
        "            window_labels_raw = labels[start : start + window_size]\n",
        "            most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "            if most_common_label in label_to_activity_idx:\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(label_to_activity_idx[most_common_label])\n",
        "            start += step\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "\n",
        "def load_mhealth_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/MHEALTH\"):\n",
        "    print(f\"\\n[MHEALTH] Loading from: {dataset_dir}\")\n",
        "    if not os.path.exists(dataset_dir):\n",
        "        return None, None, None, None, None\n",
        "    subject_files = sorted([\n",
        "        os.path.join(dataset_dir, f)\n",
        "        for f in os.listdir(dataset_dir)\n",
        "        if f.startswith(\"mHealth_subject\") and f.endswith(\".log\")\n",
        "    ])\n",
        "    if not subject_files:\n",
        "        return None, None, None, None, None\n",
        "    print(f\"  Found {len(subject_files)} subject files\")\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 50\n",
        "    step = 25\n",
        "    for idx, file_path in enumerate(subject_files):\n",
        "        print(f\"  [{idx+1}/{len(subject_files)}] Processing: {os.path.basename(file_path)}\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, engine='python', dtype=np.float32)\n",
        "            df = df.ffill().bfill()\n",
        "            if df.shape[1] < 24:\n",
        "                continue\n",
        "            labels = df.iloc[:, 23].values.astype(int)\n",
        "            imu_cols = [0, 1, 2] + list(range(5, 23))\n",
        "            features = df.iloc[:, imu_cols].values\n",
        "            valid_indices = np.where(labels != 0)[0]\n",
        "            if len(valid_indices) == 0:\n",
        "                continue\n",
        "            features = features[valid_indices, :]\n",
        "            labels = labels[valid_indices]\n",
        "            if len(features) < window_size:\n",
        "                continue\n",
        "            start = 0\n",
        "            while start + window_size <= len(features):\n",
        "                window_data = features[start : start + window_size, :]\n",
        "                window_labels_raw = labels[start : start + window_size]\n",
        "                most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(most_common_label)\n",
        "                start += step\n",
        "        except:\n",
        "            continue\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    mhealth_activity_mapping = {\n",
        "        1: 'Standing still', 2: 'Sitting and relaxing', 3: 'Lying down', 4: 'Walking',\n",
        "        5: 'Climbing stairs', 6: 'Waist bends forward', 7: 'Frontal elevation of arms',\n",
        "        8: 'Knees bending', 9: 'Cycling', 10: 'Jogging', 11: 'Running', 12: 'Jump front & back'\n",
        "    }\n",
        "    activity_labels = []\n",
        "    class_names = list(label_encoder.classes_)\n",
        "    for encoded_idx in range(len(class_names)):\n",
        "        original_label = class_names[encoded_idx]\n",
        "        activity_labels.append(mhealth_activity_mapping.get(original_label, f\"Unknown_Activity_{original_label}\"))\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "\n",
        "def slide_window(data, w_s, stride):\n",
        "    windows = []\n",
        "    start = 0\n",
        "    while start + w_s <= len(data):\n",
        "        windows.append(data[start:start + w_s, :])\n",
        "        start += stride\n",
        "    if not windows:\n",
        "        return np.array([])\n",
        "    return np.array(windows)\n",
        "\n",
        "\n",
        "def load_mobiact_sensor_file(path):\n",
        "    data = []\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            in_data_section = False\n",
        "            for line in f:\n",
        "                if line.startswith('@DATA'):\n",
        "                    in_data_section = True\n",
        "                    continue\n",
        "                if not in_data_section:\n",
        "                    continue\n",
        "                parts = line.strip().split(',')\n",
        "                if len(parts) == 4:\n",
        "                    try:\n",
        "                        data.append([float(p) for p in parts])\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    except Exception as e:\n",
        "        return None\n",
        "    if not data:\n",
        "        return None\n",
        "    return np.array(data, dtype=np.float32)\n",
        "\n",
        "\n",
        "def load_mobiact_data(data_path, w_s=100, stride=50):\n",
        "    print(f\"\\n[MobiAct] Loading from: {data_path}\")\n",
        "    ADL_CODES = ['STD', 'WAL', 'JOG', 'JUM', 'STU', 'STN', 'SCH', 'CSI', 'CSO']\n",
        "    ALL_ACTIVITIES = ADL_CODES\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(ALL_ACTIVITIES)\n",
        "    activity_names = list(label_encoder.classes_)\n",
        "    subject_dirs = sorted(glob_module.glob(os.path.join(data_path, 'sub*')))\n",
        "    subjects_to_use = []\n",
        "    for sub_dir in subject_dirs:\n",
        "        if os.path.isdir(os.path.join(sub_dir, 'ADL')):\n",
        "            subjects_to_use.append(os.path.basename(sub_dir))\n",
        "    print(f\"  Found {len(subjects_to_use)} subjects\")\n",
        "    all_data_for_scaler = []\n",
        "    all_windows, all_labels = [], []\n",
        "    temp_data_store = []\n",
        "    for sub_idx, sub_name in enumerate(subjects_to_use):\n",
        "        print(f\"  [{sub_idx+1}/{len(subjects_to_use)}] Processing: {sub_name}\")\n",
        "        subject_id_match = re.search(r'(\\d+)', sub_name)\n",
        "        if not subject_id_match:\n",
        "            continue\n",
        "        subject_id = int(subject_id_match.group(0))\n",
        "        for act_type_folder in ['ADL']:\n",
        "            act_folders_path = os.path.join(data_path, sub_name, act_type_folder, '*')\n",
        "            for act_folder_path in glob_module.glob(act_folders_path):\n",
        "                act_code = os.path.basename(act_folder_path)\n",
        "                if act_code not in ALL_ACTIVITIES:\n",
        "                    continue\n",
        "                label = label_encoder.transform([act_code])[0]\n",
        "                trial_files = glob_module.glob(os.path.join(act_folder_path, f'{act_code}_acc_{subject_id}_*.txt'))\n",
        "                trials = sorted(list(set([f.split('_')[-1].split('.')[0] for f in trial_files])))\n",
        "                for trial in trials:\n",
        "                    acc_file = os.path.join(act_folder_path, f'{act_code}_acc_{subject_id}_{trial}.txt')\n",
        "                    gyro_file = os.path.join(act_folder_path, f'{act_code}_gyro_{subject_id}_{trial}.txt')\n",
        "                    ori_file = os.path.join(act_folder_path, f'{act_code}_ori_{subject_id}_{trial}.txt')\n",
        "                    if not all(os.path.exists(f) for f in [acc_file, gyro_file, ori_file]):\n",
        "                        continue\n",
        "                    data_acc = load_mobiact_sensor_file(acc_file)\n",
        "                    data_gyro = load_mobiact_sensor_file(gyro_file)\n",
        "                    data_ori = load_mobiact_sensor_file(ori_file)\n",
        "                    if any(d is None for d in [data_acc, data_gyro, data_ori]):\n",
        "                        continue\n",
        "                    L = min(len(data_acc), len(data_gyro), len(data_ori))\n",
        "                    if L < w_s:\n",
        "                        continue\n",
        "                    combined_data = np.hstack((data_acc[:L, 1:], data_gyro[:L, 1:], data_ori[:L, 1:]))\n",
        "                    combined_data = combined_data.astype(np.float32)\n",
        "                    combined_data = pd.DataFrame(combined_data).ffill().bfill().values\n",
        "                    if np.isnan(combined_data).any():\n",
        "                        continue\n",
        "                    all_data_for_scaler.append(combined_data)\n",
        "                    temp_data_store.append({'data': combined_data, 'label': label})\n",
        "    if not all_data_for_scaler:\n",
        "        return None, None, None, None, None\n",
        "    scaler = StandardScaler().fit(np.vstack(all_data_for_scaler))\n",
        "    for item in temp_data_store:\n",
        "        scaled_data = scaler.transform(item['data'])\n",
        "        scaled_data = np.nan_to_num(scaled_data)\n",
        "        windows = slide_window(scaled_data, w_s, stride)\n",
        "        if windows.shape[0] > 0:\n",
        "            all_windows.append(windows)\n",
        "            all_labels.extend([item['label']] * windows.shape[0])\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "    X_windowed = np.vstack(all_windows).astype(np.float32)\n",
        "    X_windowed = np.transpose(X_windowed, (0, 2, 1))\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_names\n",
        "\n",
        "\n",
        "class MotionSenseLoader:\n",
        "    def __init__(self, frame_len, feature_name, N_classes):\n",
        "        self.feature_names = feature_name\n",
        "        self.N_Feature = len(feature_name)\n",
        "        self.frame_length = frame_len\n",
        "        self.hop_size = frame_len//2\n",
        "        self.N_classes = N_classes\n",
        "        self.label_encoder = OneHotEncoder(sparse_output=False)\n",
        "    def framing(self, signal):\n",
        "        shape = ((signal.shape[0] - self.frame_length) // self.hop_size + 1, self.frame_length)\n",
        "        strides = (signal.strides[0] * self.hop_size, signal.strides[0])\n",
        "        return np.lib.stride_tricks.as_strided(signal, shape=shape, strides=strides)\n",
        "    def create_label(self, label): return self.label_encoder.fit_transform(label)\n",
        "    def load_trainings_data(self, files, label_frame):\n",
        "        label = self.create_label(label_frame)\n",
        "        self.trainings_data, self.trainings_label = self.load_data(files, label)\n",
        "    def load_validation_data(self, files, label_frame):\n",
        "        label = self.label_encoder.transform(label_frame)\n",
        "        self.validation_data, self.validation_label = self.load_data(files, label)\n",
        "    def load_data(self, files, label):\n",
        "        feature_matrix, label_matrix = None, None\n",
        "        for i in range(len(files)):\n",
        "            if i % 50 == 0:\n",
        "                print(f\"    Processing file {i+1}/{len(files)}\")\n",
        "            try: tmp_data = pd.read_csv(files[i], engine='python')\n",
        "            except: continue\n",
        "            N_Blocks = 1+(np.shape(tmp_data)[0]-self.frame_length)//self.hop_size\n",
        "            if N_Blocks <= 0: continue\n",
        "            tmp_feature_mat = np.zeros((N_Blocks, self.frame_length, self.N_Feature))\n",
        "            tmp_label_vec = np.zeros((N_Blocks, self.N_classes))\n",
        "            for j in range(N_Blocks): tmp_label_vec[j, :] = label[i, :]\n",
        "            for idf, feat in enumerate(self.feature_names):\n",
        "                frame_matrix = self.framing(tmp_data[feat].to_numpy())\n",
        "                tmp_feature_mat[:, :, idf] = frame_matrix[:N_Blocks]\n",
        "            if feature_matrix is None:\n",
        "                feature_matrix = tmp_feature_mat\n",
        "                label_matrix = tmp_label_vec\n",
        "            else:\n",
        "                feature_matrix = np.append(feature_matrix, tmp_feature_mat, axis=0)\n",
        "                label_matrix = np.append(label_matrix, tmp_label_vec, axis=0)\n",
        "        return feature_matrix, label_matrix\n",
        "\n",
        "\n",
        "def load_motionsense_data(root_path='/content/drive/MyDrive/HAR_Dataset/MOTIONSENSE'):\n",
        "    print(f\"\\n[MotionSense] Loading from: {root_path}\")\n",
        "    files, label = [], []\n",
        "    for dirname, _, filenames in os.walk(root_path):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.csv') and not filename.startswith('.'):\n",
        "                full_path = os.path.join(dirname, filename)\n",
        "                if 'sub_' in filename:\n",
        "                    files.append(full_path)\n",
        "                    parent_dir = os.path.basename(os.path.dirname(full_path))\n",
        "                    if '_' in parent_dir: label.append(parent_dir.split('_')[0])\n",
        "                    else: files.pop()\n",
        "    if not files: return None, None, None, None, None\n",
        "    print(f\"  Found {len(files)} CSV files\")\n",
        "    label_frame = pd.DataFrame(label, columns=['act'])\n",
        "    files_train, files_valid, y_train_raw, y_valid_raw = train_test_split(files, label_frame, test_size=0.2, random_state=0)\n",
        "    Feature = ['attitude.roll','attitude.pitch','attitude.yaw','gravity.x','gravity.y','gravity.z',\n",
        "               'rotationRate.x','rotationRate.y','rotationRate.z','userAcceleration.x','userAcceleration.y','userAcceleration.z']\n",
        "    N_classes = 6\n",
        "    loader = MotionSenseLoader(128, Feature, N_classes)\n",
        "    print(f\"  Processing training files...\")\n",
        "    loader.load_trainings_data(files_train, y_train_raw)\n",
        "    print(f\"  Processing validation files...\")\n",
        "    loader.load_validation_data(files_valid, y_valid_raw)\n",
        "    X_train = loader.trainings_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    X_test = loader.validation_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    y_train = np.argmax(loader.trainings_label, axis=1)\n",
        "    y_test = np.argmax(loader.validation_label, axis=1)\n",
        "    activity_names = list(loader.label_encoder.categories_[0])\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_names\n",
        "\n",
        "\n",
        "def load_unimib_shar_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/UNIMIB (1)\"):\n",
        "    print(f\"\\n[UNIMIB] Loading from: {dataset_dir}\")\n",
        "    train_path = os.path.join(dataset_dir, \"unimib_train.csv\")\n",
        "    test_path = os.path.join(dataset_dir, \"unimib_test.csv\")\n",
        "    val_path = os.path.join(dataset_dir, \"unimib_val.csv\")\n",
        "    if not os.path.exists(train_path): return None, None, None, None, None\n",
        "    def process_unimib_csv(path):\n",
        "        if not os.path.exists(path): return np.array([]), np.array([])\n",
        "        print(f\"  Processing: {os.path.basename(path)}\")\n",
        "        df = pd.read_csv(path)\n",
        "        df = df.sort_values(by=['ID', 't'])\n",
        "        X_list, y_list = [], []\n",
        "        for _, group in df.groupby('ID'):\n",
        "            X_list.append(group[['ax', 'ay', 'az']].values.astype(np.float32))\n",
        "            y_list.append(group['label'].iloc[0])\n",
        "        return np.array(X_list), np.array(y_list)\n",
        "    X_train, y_train_raw = process_unimib_csv(train_path)\n",
        "    X_test, y_test_raw = process_unimib_csv(test_path)\n",
        "    if os.path.exists(val_path):\n",
        "        X_val, y_val_raw = process_unimib_csv(val_path)\n",
        "        if len(X_val) > 0:\n",
        "            X_test = np.concatenate((X_test, X_val), axis=0)\n",
        "            y_test_raw = np.concatenate((y_test_raw, y_val_raw), axis=0)\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train_raw)\n",
        "    y_test = le.transform(y_test_raw)\n",
        "    class_names = [str(c) for c in le.classes_]\n",
        "    B_train, T, C = X_train.shape\n",
        "    B_test, _, _ = X_test.shape\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train.reshape(B_train, -1)).reshape(B_train, T, C).transpose(0, 2, 1)\n",
        "    X_test = scaler.transform(X_test.reshape(B_test, -1)).reshape(B_test, T, C).transpose(0, 2, 1)\n",
        "    print(f\"  Completed: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, class_names\n",
        "\n",
        "\n",
        "SENSOR_CONFIG = {\n",
        "    'UCI-HAR': {'acc_indices': [0, 1, 2, 3, 4, 5], 'gyro_indices': [6, 7, 8]},\n",
        "    'WISDM': {'acc_indices': [0, 1, 2], 'gyro_indices': []},\n",
        "    'DSADS': {'acc_indices': [0, 1, 2, 9, 10, 11, 18, 19, 20, 27, 28, 29, 36, 37, 38], 'gyro_indices': [3, 4, 5, 12, 13, 14, 21, 22, 23, 30, 31, 32, 39, 40, 41]},\n",
        "    'PAMAP2': {'acc_indices': [0, 1, 2, 6, 7, 8, 12, 13, 14], 'gyro_indices': [3, 4, 5, 9, 10, 11, 15, 16, 17]},\n",
        "    'MHEALTH': {'acc_indices': [0, 1, 2, 9, 10, 11], 'gyro_indices': [6, 7, 8, 15, 16, 17]},\n",
        "    'MOBIACT': {'acc_indices': [0, 1, 2], 'gyro_indices': [3, 4, 5]},\n",
        "    'MOTIONSENSE': {'acc_indices': [3, 4, 5, 9, 10, 11], 'gyro_indices': [6, 7, 8]},\n",
        "    'UNIMIB': {'acc_indices': [0, 1, 2], 'gyro_indices': []},\n",
        "}\n",
        "\n",
        "\n",
        "class RelativeEnergyPhysics(nn.Module):\n",
        "    def __init__(self, acc_indices, gyro_indices, learnable=True):\n",
        "        super().__init__()\n",
        "        self.acc_indices = acc_indices\n",
        "        self.gyro_indices = gyro_indices\n",
        "        self.m = nn.Parameter(torch.tensor(1.0), requires_grad=learnable)\n",
        "        self.I = nn.Parameter(torch.tensor(1.0), requires_grad=learnable)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m_pos = F.softplus(self.m)\n",
        "        I_pos = F.softplus(self.I)\n",
        "        if len(self.acc_indices) > 0:\n",
        "            acc_data = x[:, :, self.acc_indices]\n",
        "            n_acc_sensors = len(self.acc_indices) // 3\n",
        "            if n_acc_sensors > 0:\n",
        "                acc_reshaped = acc_data.view(x.shape[0], x.shape[1], n_acc_sensors, 3)\n",
        "                acc_magnitude = (acc_reshaped ** 2).sum(dim=-1).mean(dim=-1, keepdim=True)\n",
        "            else:\n",
        "                acc_magnitude = torch.zeros(x.shape[0], x.shape[1], 1, device=x.device)\n",
        "        else:\n",
        "            acc_magnitude = torch.zeros(x.shape[0], x.shape[1], 1, device=x.device)\n",
        "        E_kinetic_proxy = 0.5 * m_pos * acc_magnitude\n",
        "        if len(self.gyro_indices) > 0:\n",
        "            gyro_data = x[:, :, self.gyro_indices]\n",
        "            n_gyro_sensors = len(self.gyro_indices) // 3\n",
        "            if n_gyro_sensors > 0:\n",
        "                gyro_reshaped = gyro_data.view(x.shape[0], x.shape[1], n_gyro_sensors, 3)\n",
        "                gyro_magnitude = (gyro_reshaped ** 2).sum(dim=-1).mean(dim=-1, keepdim=True)\n",
        "            else:\n",
        "                gyro_magnitude = torch.zeros(x.shape[0], x.shape[1], 1, device=x.device)\n",
        "        else:\n",
        "            gyro_magnitude = torch.zeros(x.shape[0], x.shape[1], 1, device=x.device)\n",
        "        E_rotational_proxy = 0.5 * I_pos * gyro_magnitude\n",
        "        E_relative = E_kinetic_proxy + E_rotational_proxy\n",
        "        return E_relative\n",
        "\n",
        "\n",
        "class PotentialEnergyField(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, sensor_config, use_physics=True, learnable_physics=True):\n",
        "        super().__init__()\n",
        "        self.use_physics = use_physics\n",
        "        if use_physics:\n",
        "            self.physics = RelativeEnergyPhysics(\n",
        "                acc_indices=sensor_config['acc_indices'],\n",
        "                gyro_indices=sensor_config['gyro_indices'],\n",
        "                learnable=learnable_physics\n",
        "            )\n",
        "        self.energy_net = nn.Sequential(\n",
        "            nn.Linear(input_dim + (1 if use_physics else 0), hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_physics:\n",
        "            E_physics = self.physics(x)\n",
        "            x_augmented = torch.cat([x, E_physics], dim=-1)\n",
        "        else:\n",
        "            x_augmented = x\n",
        "        E_learned = self.energy_net(x_augmented)\n",
        "        return E_learned\n",
        "\n",
        "\n",
        "class EnergyGradientFlow(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, sensor_config, use_physics=True, use_physics_gradient=True, learnable_physics=True):\n",
        "        super().__init__()\n",
        "        self.acc_indices = sensor_config['acc_indices']\n",
        "        self.gyro_indices = sensor_config['gyro_indices']\n",
        "        self.input_dim = input_dim\n",
        "        self.use_physics = use_physics\n",
        "        self.use_physics_gradient = use_physics_gradient\n",
        "        if use_physics:\n",
        "            self.physics = RelativeEnergyPhysics(\n",
        "                acc_indices=sensor_config['acc_indices'],\n",
        "                gyro_indices=sensor_config['gyro_indices'],\n",
        "                learnable=learnable_physics\n",
        "            )\n",
        "        self.gradient_net = nn.Sequential(\n",
        "            nn.Linear(input_dim + (1 if use_physics else 0), hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_physics:\n",
        "            E_physics = self.physics(x)\n",
        "            x_augmented = torch.cat([x, E_physics], dim=-1)\n",
        "        else:\n",
        "            x_augmented = x\n",
        "        gradient = self.gradient_net(x_augmented)\n",
        "        if self.use_physics and self.use_physics_gradient:\n",
        "            m_pos = F.softplus(self.physics.m)\n",
        "            I_pos = F.softplus(self.physics.I)\n",
        "            physics_gradient = torch.zeros_like(x)\n",
        "            if len(self.acc_indices) > 0:\n",
        "                acc_data = x[:, :, self.acc_indices]\n",
        "                force_proxy = acc_data * m_pos\n",
        "                physics_gradient[:, :, self.acc_indices] = force_proxy\n",
        "            if len(self.gyro_indices) > 0:\n",
        "                gyro_data = x[:, :, self.gyro_indices]\n",
        "                torque_proxy = gyro_data * I_pos\n",
        "                physics_gradient[:, :, self.gyro_indices] = torque_proxy\n",
        "            return gradient + 0.1 * physics_gradient\n",
        "        return gradient\n",
        "\n",
        "\n",
        "class LandscapeGeometryEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        combined_dim = input_dim * 2 + 1\n",
        "        self.input_proj = nn.Conv1d(combined_dim, hidden_dim, kernel_size=1)\n",
        "        self.conv = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)\n",
        "\n",
        "    def forward(self, energy, gradient, x_original):\n",
        "        landscape_state = torch.cat([x_original, gradient, energy], dim=-1)\n",
        "        x = self.input_proj(landscape_state.transpose(1, 2))\n",
        "        x = self.conv(x)\n",
        "        x = self.norm(x.transpose(1, 2)).transpose(1, 2)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout(x)\n",
        "        h_attn_in = x.transpose(1, 2)\n",
        "        h_attn_out, _ = self.attention(h_attn_in, h_attn_in, h_attn_in)\n",
        "        return h_attn_out\n",
        "\n",
        "\n",
        "class SimpleLandscapeEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        combined_dim = input_dim * 2 + 1\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(combined_dim, hidden_dim, kernel_size=5, padding=2),\n",
        "            nn.LayerNorm([hidden_dim]),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2),\n",
        "            nn.LayerNorm([hidden_dim]),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, energy, gradient, x_original):\n",
        "        landscape_state = torch.cat([x_original, gradient, energy], dim=-1)\n",
        "        x = self.encoder(landscape_state.transpose(1, 2))\n",
        "        return x.transpose(1, 2)\n",
        "\n",
        "\n",
        "class MIELHAR(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, sensor_config,\n",
        "                 use_physics=True, learnable_physics=True, use_physics_gradient=True,\n",
        "                 use_landscape=True, use_energy_loss=True):\n",
        "        super().__init__()\n",
        "        self.use_energy_loss = use_energy_loss\n",
        "        self.potential_field = PotentialEnergyField(input_dim, hidden_dim, sensor_config, use_physics, learnable_physics)\n",
        "        self.gradient_flow = EnergyGradientFlow(input_dim, hidden_dim, sensor_config, use_physics, use_physics_gradient, learnable_physics)\n",
        "        if use_landscape:\n",
        "            self.landscape_encoder = LandscapeGeometryEncoder(input_dim, hidden_dim)\n",
        "        else:\n",
        "            self.landscape_encoder = SimpleLandscapeEncoder(input_dim, hidden_dim)\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "        self.energy_reg_weight = 0.01\n",
        "\n",
        "    def forward(self, x, return_energy=False):\n",
        "        energy = self.potential_field(x)\n",
        "        gradient = self.gradient_flow(x)\n",
        "        landscape_features = self.landscape_encoder(energy, gradient, x)\n",
        "        global_features = self.global_pool(landscape_features.transpose(1, 2)).squeeze(-1)\n",
        "        logits = self.classifier(global_features)\n",
        "        if return_energy:\n",
        "            return logits, energy, gradient\n",
        "        return logits\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        energy = self.potential_field(x)\n",
        "        gradient = self.gradient_flow(x)\n",
        "        landscape_features = self.landscape_encoder(energy, gradient, x)\n",
        "        global_features = self.global_pool(landscape_features.transpose(1, 2)).squeeze(-1)\n",
        "        return global_features\n",
        "\n",
        "    def compute_energy_loss(self, energy, gradient, labels):\n",
        "        energy_diff = energy[:, 1:] - energy[:, :-1]\n",
        "        smoothness_loss = torch.mean(energy_diff ** 2)\n",
        "        gradient_mag = torch.norm(gradient, dim=-1)\n",
        "        gradient_loss = torch.mean(gradient_mag)\n",
        "        return smoothness_loss + 0.1 * gradient_loss\n",
        "\n",
        "\n",
        "def plot_tsne(features, labels, activity_names, save_path, samples_per_class=600):\n",
        "    sampled_features, sampled_labels = [], []\n",
        "    for i in range(len(activity_names)):\n",
        "        class_mask = (labels == i)\n",
        "        class_indices = np.where(class_mask)[0]\n",
        "        if len(class_indices) > 0:\n",
        "            if len(class_indices) >= samples_per_class:\n",
        "                selected_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
        "            else:\n",
        "                selected_indices = class_indices\n",
        "            sampled_features.append(features[selected_indices])\n",
        "            sampled_labels.append(labels[selected_indices])\n",
        "    features_sampled = np.vstack(sampled_features)\n",
        "    labels_sampled = np.concatenate(sampled_labels)\n",
        "    n_samples = features_sampled.shape[0]\n",
        "    perplexity = min(30, n_samples - 1)\n",
        "    features_2d = TSNE(n_components=2, perplexity=perplexity, learning_rate=200, random_state=42).fit_transform(features_sampled)\n",
        "    num_classes = len(activity_names)\n",
        "    cmap = plt.cm.get_cmap('tab20', num_classes)\n",
        "    colors = [cmap(i) for i in range(num_classes)]\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    for i, activity in enumerate(activity_names):\n",
        "        mask = (labels_sampled == i)\n",
        "        if np.any(mask):\n",
        "            plt.scatter(features_2d[mask, 0], features_2d[mask, 1],\n",
        "                       color=colors[i], marker='o', s=19, alpha=0.6, label=activity)\n",
        "    plt.legend(title=\"Activities\", fontsize=8, loc='best', ncol=2)\n",
        "    plt.xlabel(\"t-SNE Component 1\", fontsize=12)\n",
        "    plt.ylabel(\"t-SNE Component 2\", fontsize=12)\n",
        "    plt.title(\"t-SNE Visualization\", fontsize=14)\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, activity_names, save_path):\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    num_classes = len(activity_names)\n",
        "    labels = []\n",
        "    for name in activity_names:\n",
        "        if len(name) > 15:\n",
        "            words = name.split()\n",
        "            if len(words) > 1:\n",
        "                mid = len(words) // 2\n",
        "                labels.append(' '.join(words[:mid]) + '\\n' + ' '.join(words[mid:]))\n",
        "            else:\n",
        "                labels.append(name[:15] + '\\n' + name[15:])\n",
        "        else:\n",
        "            labels.append(name)\n",
        "    df = pd.DataFrame(cm_normalized, index=labels, columns=labels)\n",
        "    annot = df.copy().astype(str)\n",
        "    for i in range(df.shape[0]):\n",
        "        for j in range(df.shape[1]):\n",
        "            v = df.iloc[i, j]\n",
        "            annot.iloc[i, j] = f\"{v:.2f}\"\n",
        "    figsize = max(8, num_classes * 0.5)\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    sns.heatmap(df, annot=annot.values, fmt=\"\", cmap=\"Blues\", cbar=True,\n",
        "                annot_kws={\"size\": max(6, 12 - num_classes // 3)}, vmin=0, vmax=1)\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=max(6, 11 - num_classes // 4))\n",
        "    plt.yticks(rotation=0, fontsize=max(6, 11 - num_classes // 4))\n",
        "    for spine in plt.gca().spines.values():\n",
        "        spine.set_visible(True)\n",
        "        spine.set_linewidth(0.5)\n",
        "        spine.set_edgecolor('black')\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.title('Confusion Matrix', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, device, use_amp=True):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
        "            if use_amp:\n",
        "                with autocast('cuda'):\n",
        "                    logits = model(batch_x)\n",
        "            else:\n",
        "                logits = model(batch_x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    return acc, f1, precision, recall\n",
        "\n",
        "\n",
        "def extract_features_and_predictions(model, data_loader, device, use_amp=True):\n",
        "    model.eval()\n",
        "    all_features, all_preds, all_labels = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in data_loader:\n",
        "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
        "            if use_amp:\n",
        "                with autocast('cuda'):\n",
        "                    features = model.extract_features(batch_x)\n",
        "                    logits = model(batch_x)\n",
        "            else:\n",
        "                features = model.extract_features(batch_x)\n",
        "                logits = model(batch_x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_features.append(features.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "    return np.vstack(all_features), np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "\n",
        "def compute_flops_params(model, input_shape, device):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "    flops_m = macs * 2 / 1e6\n",
        "    params_m = params / 1e6\n",
        "    return flops_m, params_m\n",
        "\n",
        "\n",
        "def measure_inference_time(model, input_shape, device, n_runs=100, warmup=10):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_runs):\n",
        "            _ = model(dummy_input)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    return (end - start) / n_runs * 1000\n",
        "\n",
        "\n",
        "def train_single_dataset(dataset_name, X_train, y_train, X_test, y_test, activity_names, device,\n",
        "                         ablation_config, epochs=50):\n",
        "    seq_len = X_train.shape[1]\n",
        "    input_dim = X_train.shape[2]\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    sensor_config = SENSOR_CONFIG[dataset_name]\n",
        "    train_dataset = UCIHARDataset(X_train, y_train)\n",
        "    test_dataset = UCIHARDataset(X_test, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True,\n",
        "                             num_workers=4, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False,\n",
        "                            num_workers=4, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
        "    model = MIELHAR(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dim=128,\n",
        "        num_classes=num_classes,\n",
        "        sensor_config=sensor_config,\n",
        "        use_physics=ablation_config['use_physics'],\n",
        "        learnable_physics=ablation_config['learnable_physics'],\n",
        "        use_physics_gradient=ablation_config['use_physics_gradient'],\n",
        "        use_landscape=ablation_config['use_landscape'],\n",
        "        use_energy_loss=ablation_config['use_energy_loss']\n",
        "    ).to(device)\n",
        "    flops_m, params_m = compute_flops_params(model, (seq_len, input_dim), device)\n",
        "    inf_time = measure_inference_time(model, (seq_len, input_dim), device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    scaler = GradScaler('cuda')\n",
        "    best_acc = 0.0\n",
        "    best_metrics = {}\n",
        "    best_model_state = None\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {dataset_name} - {ablation_config['name']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Params: {params_m:.2f}M | FLOPs: {flops_m:.2f}M | Inf: {inf_time:.2f}ms\")\n",
        "    print(f\"Input: ({seq_len}, {input_dim}) | Classes: {num_classes}\")\n",
        "    print(f\"{'Epoch':<8} {'LR':<10} {'Loss':<10} {'Acc':<10} {'F1':<10} {'Prec':<10} {'Rec':<10}\")\n",
        "    print(\"-\" * 60)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        annealing_weight = min(1.0, epoch / (epochs * 0.5))\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast('cuda'):\n",
        "                logits, energy, gradient = model(batch_x, return_energy=True)\n",
        "                cls_loss = criterion(logits, batch_y)\n",
        "                if ablation_config['use_energy_loss']:\n",
        "                    energy_loss = model.compute_energy_loss(energy, gradient, batch_y)\n",
        "                    loss = cls_loss + model.energy_reg_weight * annealing_weight * energy_loss\n",
        "                else:\n",
        "                    loss = cls_loss\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "        test_acc, test_f1, test_prec, test_rec = evaluate(model, test_loader, device)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_metrics = {\n",
        "                'acc': test_acc,\n",
        "                'f1': test_f1,\n",
        "                'prec': test_prec,\n",
        "                'rec': test_rec\n",
        "            }\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            best_msg = \" (*)\"\n",
        "        else:\n",
        "            best_msg = \"\"\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
        "            print(f\"{epoch+1:<8} {current_lr:<10.6f} {total_loss/len(train_loader):<10.4f} \"\n",
        "                  f\"{test_acc:<10.4f} {test_f1:<10.4f} {test_prec:<10.4f} {test_rec:<10.4f}{best_msg}\")\n",
        "        if device.type == 'cuda' and epoch % 10 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Best - Acc: {best_metrics['acc']:.4f} | F1: {best_metrics['f1']:.4f} | Prec: {best_metrics['prec']:.4f} | Rec: {best_metrics['rec']:.4f}\")\n",
        "    print(f\"Params: {params_m:.2f}M | FLOPs: {flops_m:.2f}M | Inf: {inf_time:.2f}ms\")\n",
        "    model.load_state_dict(best_model_state)\n",
        "    features, preds, labels = extract_features_and_predictions(model, test_loader, device)\n",
        "   # cm = confusion_matrix(labels, preds)\n",
        "    #tsne_path = f\"{dataset_name}_{ablation_config['name']}_tsne.png\"\n",
        "    #cm_path = f\"{dataset_name}_{ablation_config['name']}_confusion_matrix.png\"\n",
        "    print(f\"\\nGenerating t-SNE plot for {dataset_name} - {ablation_config['name']}...\")\n",
        "    #plot_tsne(features, labels, activity_names, tsne_path)\n",
        "    #print(f\"Generating Confusion Matrix for {dataset_name} - {ablation_config['name']}...\")\n",
        "    #plot_confusion_matrix(cm, activity_names, cm_path)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    return {\n",
        "        'Dataset': dataset_name,\n",
        "        'Config': ablation_config['name'],\n",
        "        'Params(M)': round(params_m, 2),\n",
        "        'FLOPs(M)': round(flops_m, 2),\n",
        "        'Inf(ms)': round(inf_time, 2),\n",
        "        'Acc': round(best_metrics['acc'], 4),\n",
        "        'F1': round(best_metrics['f1'], 4),\n",
        "        'Prec': round(best_metrics['prec'], 4),\n",
        "        'Rec': round(best_metrics['rec'], 4)\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"=\" * 80)\n",
        "    print(\"MIEL-HAR Multi-Dataset Ablation Study (GPU Optimized)\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Device: {device}\\n\")\n",
        "    if device.type == 'cuda':\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"cuDNN Enabled: {torch.backends.cudnn.enabled}\")\n",
        "        print(f\"cuDNN Benchmark: {torch.backends.cudnn.benchmark}\\n\")\n",
        "\n",
        "    datasets_config = [\n",
        "        ('UCI-HAR', load_uci_har, '/content/drive/MyDrive/HAR_Dataset/UCI'),\n",
        "        ('WISDM', load_wisdm_data, '/content/drive/MyDrive/HAR_Dataset/WISDM'),\n",
        "        ('PAMAP2', load_pamap2_data, '/content/drive/MyDrive/HAR_Dataset/PAMAP2'),\n",
        "        ('MHEALTH', load_mhealth_data, '/content/drive/MyDrive/HAR_Dataset/MHEALTH'),\n",
        "        ('MOBIACT', load_mobiact_data, '/content/drive/MyDrive/HAR_Dataset/MOBIACT'),\n",
        "        ('MOTIONSENSE', load_motionsense_data, '/content/drive/MyDrive/HAR_Dataset/MOTIONSENSE'),\n",
        "        ('UNIMIB', load_unimib_shar_data, '/content/drive/MyDrive/HAR_Dataset/UNIMIB (1)')\n",
        "    ]\n",
        "\n",
        "    ablation_configs = [\n",
        "        {\n",
        "            'name': 'Full Model (Ours)',\n",
        "            'use_physics': True,\n",
        "            'learnable_physics': True,\n",
        "            'use_physics_gradient': True,\n",
        "            'use_landscape': True,\n",
        "            'use_energy_loss': True\n",
        "        },\n",
        "        {\n",
        "            'name': 'w/o Physics Priors',\n",
        "            'use_physics': False,\n",
        "            'learnable_physics': False,\n",
        "            'use_physics_gradient': False,\n",
        "            'use_landscape': True,\n",
        "            'use_energy_loss': True\n",
        "        },\n",
        "        {\n",
        "            'name': 'Fixed Physics',\n",
        "            'use_physics': True,\n",
        "            'learnable_physics': False,\n",
        "            'use_physics_gradient': True,\n",
        "            'use_landscape': True,\n",
        "            'use_energy_loss': True\n",
        "        },\n",
        "        {\n",
        "            'name': 'w/o Physics Gradient',\n",
        "            'use_physics': True,\n",
        "            'learnable_physics': True,\n",
        "            'use_physics_gradient': False,\n",
        "            'use_landscape': True,\n",
        "            'use_energy_loss': True\n",
        "        },\n",
        "        {\n",
        "            'name': 'w/o Landscape Enc',\n",
        "            'use_physics': True,\n",
        "            'learnable_physics': True,\n",
        "            'use_physics_gradient': True,\n",
        "            'use_landscape': False,\n",
        "            'use_energy_loss': True\n",
        "        },\n",
        "        {\n",
        "            'name': 'w/o Energy Loss',\n",
        "            'use_physics': True,\n",
        "            'learnable_physics': True,\n",
        "            'use_physics_gradient': True,\n",
        "            'use_landscape': True,\n",
        "            'use_energy_loss': False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    all_datasets = {}\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Loading All Datasets\")\n",
        "    print(\"=\" * 80)\n",
        "    for dataset_name, loader_func, data_path in datasets_config:\n",
        "        try:\n",
        "            print(f\"\\n{'#'*60}\")\n",
        "            print(f\"Loading {dataset_name}...\")\n",
        "            print(f\"{'#'*60}\")\n",
        "            data = loader_func(data_path)\n",
        "            if data is None or data[0] is None:\n",
        "                print(f\"Failed to load {dataset_name}\")\n",
        "                continue\n",
        "            X_train, y_train, X_test, y_test, activity_names = data\n",
        "            num_train_classes = len(np.unique(y_train))\n",
        "            num_test_classes = len(np.unique(y_test))\n",
        "            print(f\"Train: {X_train.shape} | Classes: {num_train_classes}\")\n",
        "            print(f\"Test: {X_test.shape} | Classes: {num_test_classes}\")\n",
        "            print(f\"Activity Names: {activity_names}\")\n",
        "            train_class_dist = Counter(y_train)\n",
        "            test_class_dist = Counter(y_test)\n",
        "            print(f\"Train class distribution: {dict(sorted(train_class_dist.items()))}\")\n",
        "            print(f\"Test class distribution: {dict(sorted(test_class_dist.items()))}\")\n",
        "            all_datasets[dataset_name] = {\n",
        "                'X_train': X_train,\n",
        "                'y_train': y_train,\n",
        "                'X_test': X_test,\n",
        "                'y_test': y_test,\n",
        "                'activity_names': activity_names\n",
        "            }\n",
        "            gc.collect()\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {dataset_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Successfully loaded {len(all_datasets)} datasets\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    results = []\n",
        "    for dataset_name, dataset_data in all_datasets.items():\n",
        "        for ablation_config in ablation_configs:\n",
        "            try:\n",
        "                result = train_single_dataset(\n",
        "                    dataset_name,\n",
        "                    dataset_data['X_train'],\n",
        "                    dataset_data['y_train'],\n",
        "                    dataset_data['X_test'],\n",
        "                    dataset_data['y_test'],\n",
        "                    dataset_data['activity_names'],\n",
        "                    device,\n",
        "                    ablation_config,\n",
        "                    epochs=50\n",
        "                )\n",
        "                results.append(result)\n",
        "                if device.type == 'cuda':\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "            except Exception as e:\n",
        "                print(f\"Error training {dataset_name} with {ablation_config['name']}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "    if results:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"FINAL RESULTS - ABLATION STUDY\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df = results_df[['Dataset', 'Config', 'Params(M)', 'FLOPs(M)', 'Inf(ms)', 'Acc', 'F1', 'Prec', 'Rec']]\n",
        "        print(results_df.to_string(index=False))\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        for dataset_name in all_datasets.keys():\n",
        "            dataset_results = results_df[results_df['Dataset'] == dataset_name]\n",
        "            if len(dataset_results) > 0:\n",
        "                print(f\"\\n{dataset_name} Results:\")\n",
        "                print(dataset_results[['Dataset', 'Config', 'Params(M)', 'FLOPs(M)', 'Inf(ms)', 'Acc', 'F1', 'Prec', 'Rec']].to_string(index=False))\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        try:\n",
        "            display(results_df)\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-NSTt0V-QS2C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}